{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion in text\n",
    "link: https://www.crowdflower.com/data-for-everyone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('./emotionanalysis/text_emotion.csv')\n",
    "#df =pd.read_csv('./emotionanalysis/Airline-Sentiment-2-w-AA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31889, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hipotesis\n",
    "df = df[(df.sentiment != \"neutral\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduccion binaria (elegir libre cuales emociones son negativas y positivas)\n",
    "* navie bayes\n",
    "* multinomial naive bayes\n",
    "* lda\n",
    "* qda\n",
    "* regresion logistica\n",
    "* svm\n",
    "* arboles de decision\n",
    "\n",
    "vs multiclass (cada emocion es una etiqueta)\n",
    "comparar los que por defecto son extentidos a multiclases:  \n",
    "* arboles de decision\n",
    "* lda  #http://multivariatestatsjl.readthedocs.io/en/latest/mclda.html\n",
    "* qda\n",
    "vs los que hay que extenderlos mediante otros metodos one vs one, one vs all ,dag:\n",
    "http://scikit-learn.org/stable/modules/multiclass.html\n",
    "* svm\n",
    "* regresion logistica\n",
    "\n",
    "no se:\n",
    "* navie bayes\n",
    "* multinomial naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def word_extractor(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ stemmer.stem(word.lower()) \\\n",
    "        for word in tknzr.tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "textos = [word_extractor(text) for text in df.content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"process_content\"] = textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = pd.DataFrame(df[msk])\n",
    "test = pd.DataFrame(df[~msk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(train.process_content)\n",
    "\n",
    "X_train = vectorizer.transform(train.process_content)\n",
    "X_test = vectorizer.transform(test.process_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sentiment = pd.factorize(train.sentiment)[0]\n",
    "test.sentiment = pd.factorize(test.sentiment)[0]\n",
    "y_train = train.sentiment.values\n",
    "y_test = test.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score C= 0.158011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty='l2',C=0.01,multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "print ('Logistic Regression accuracy score C= %f'%model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score C= 0.172805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "print ('accuracy score C= %f'%model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de palabras en el diccionario: 48212.000000\n",
      "==========  =========  ============  ===\n",
      "  Training  Palabra      Frecuencia  #\n",
      "==========  =========  ============  ===\n",
      "         1  day                3341  #\n",
      "         2  go                 3190  #\n",
      "         3  get                2616  #\n",
      "         4  wa                 2596  #\n",
      "         5  good               2268  #\n",
      "         6  work               2103  #\n",
      "         7  love               2040  #\n",
      "         8  like               1998  #\n",
      "         9  http               1811  #\n",
      "        10  got                1796  #\n",
      "==========  =========  ============  ===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dist=list(np.array(features.sum(axis=0)).reshape(-1,))\n",
    "vocab = vectorizer.get_feature_names()\n",
    "lista = zip(vocab, dist)\n",
    "lista.sort(key=lambda x: x[1])\n",
    "lista.reverse()\n",
    "\n",
    "N = 10\n",
    "pals_train = []\n",
    "count_train =[]\n",
    "for i in range(N):\n",
    "    tag, count = lista[i]\n",
    "    pals_train.append(tag)\n",
    "    count_train.append(count)\n",
    "print \"Cantidad de palabras en el diccionario: %f\"%(len(vocab))\n",
    "\n",
    "a = [range(1,11),pals_train,count_train, [\"#\",\"#\",\"#\",\"#\",\"#\",\"#\",\"#\",\"#\",\"#\",\"#\"]]\n",
    "table =  zip(*a)\n",
    "from tabulate import tabulate\n",
    "print tabulate(table, headers=[\"Training\",\"Palabra\",\"Frecuencia\",\"#\", \"Test\",\"Palabra\",\"Frecuencia\"],  tablefmt=\"rst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "folder = \"./Emolex/\"\n",
    "archivo = pd.read_csv(folder+\"NRC-Hashtag-Emotion-Lexicon-v0.2.txt\",sep='\\t',header=None)\n",
    "\n",
    "dicc_Emolex = {}\n",
    "for indice in range(archivo.shape[0]):\n",
    "    emocion,palabra,score= archivo.iloc[indice]\n",
    "    if palabra in dicc_Emolex.keys():\n",
    "        dicc_Emolex[palabra].append([emocion,score])\n",
    "\n",
    "    else:\n",
    "        dicc_Emolex[palabra] = [[emocion,score]]\n",
    "##dicc emoclex creado!\n",
    "\n",
    "emociones_contrarias = [[\"sadness\",\"joy\"],[\"disgust\",\"trust\"],[\"anger\",\"fear\"],[\"surprise\",\"anticipation\"]]\n",
    "\n",
    "def metrica(tweet_procesado):\n",
    "    score_tweet = {'sadness':[],'disgust':[],'anger':[],'surprise':[]}\n",
    "\n",
    "    score_emociones = {'anticipation':[],'joy':[],'fear':[],'disgust':[],'anger':[],'trust':[],'surprise':[],'sadness':[]}\n",
    "\n",
    "    for palabra in tweet_procesado: \n",
    "        if palabra in dicc_Emolex.keys():\n",
    "            for emocion,score in dicc_Emolex[palabra]: #elementos guardados en emolex\n",
    "                score_emociones[emocion].append(score)\n",
    "\n",
    "    #metrica\n",
    "    for emocion1,emocion2 in emociones_contrarias:\n",
    "        if score_emociones[emocion1] == [] and score_emociones[emocion2] == []:\n",
    "            metrica = 0.0\n",
    "\n",
    "        else:#no nan\n",
    "            if score_emociones[emocion1] == []: #tweet no tiene emocion1\n",
    "                score_emociones[emocion1] = [0.0]\n",
    "\n",
    "            if score_emociones[emocion2] == []:\n",
    "                score_emociones[emocion2] = [0.0]\n",
    "\n",
    "            metrica= np.sum(score_emociones[emocion1]) - np.sum(score_emociones[emocion2])\n",
    "\n",
    "            #if delta >0:\n",
    "\n",
    "             #   metrica = delta #promedio o solo suma??\n",
    "            #else:\n",
    "            #    metrica = 0.0\n",
    "        score_tweet[emocion1].append( metrica )  #cada tweet tiene una metrica\n",
    "    return score_tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#metrica para positivo y negativo\n",
    "def positive_negative(texto_preprocesado):\n",
    "    total = np.sum(metrica(texto_preprocesado).values)\n",
    "    if total >0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_negative([\"happy\",\"food\",\"eat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba ruok"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
