{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 1  </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Problemas de clasificación y  regresión.\n",
    "* Selección de atributos y parámetros de regularización en regresión lineal (Ridge y Lasso).\n",
    "* Validación cruzada.\n",
    "* PCA versus LDA. Reducción de dimensionalidad para clasificación.\n",
    "* Selección de hı́per-parámetros estructurales en Regresión Logı́stica, SVM.\n",
    "* LDA, QDA, Naive Bayes en texto\n",
    "* Clasificadores bayesianos ingenuos (Bernoulli, Multinomial)\n",
    "* Preprocesamiento de datos brutos y representaciones de entrada.\n",
    " \n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y discusión: 26 de Octubre y 29 de Octubre (13:00 PM)\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea1-INF393-II-2018]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Aprendizaje en regresión lineal  \n",
    "[2.](#segundo) Análisis de audios como datos brutos  \n",
    "[3.](#tercero) Análisis de emociones en tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item 0 \n",
    "lda y qda (fronteras de clasificacion)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Aprendizaje en regresión lineal.\n",
    "\n",
    "buscar dataset entretenido...\n",
    "\n",
    "regularizacion en regresion lineal\n",
    "\n",
    "selecc de atributos\n",
    "\n",
    "cross validation\n",
    "\n",
    "> Realice una regresión lineal de mı́nimos cuadrados básica. Explique la importancia/conveniencia del\n",
    "paso 4 y los argumentos que se deben entregar a la función que implementa la regresión lineal.\n",
    "\n",
    "> Construya una tabla con los pesos y Z-score correspondientes a cada predictor (variable). ¿Qué variables\n",
    "están más correlacionadas con la respuesta? Si usáramos un nivel de significación del 5%. ¿Qué es lo\n",
    "que observa y cuál puede ser la causa?\n",
    "\n",
    "> a) Construya una función que implemente *Forward Step-wise Selection* (FSS). Es decir, partiendo con un\n",
    "modelo sin predictores (variables), agregue un predictor a la vez, re-ajustando el modelo de regresión\n",
    "en cada paso. Para seleccionar localmente una variable, proponga/implemente un criterio distinto al\n",
    "utilizado en el código de ejemplo. Construya un gráfico que muestre el error de entrenamiento y el error\n",
    "de pruebas como función del número de variables en el modelo. Ordene el eje $x$ de menor a mayor.\n",
    "\n",
    "> b) Ajuste un modelo lineal utilizando “*Ridge Regression*”, es decir, regularizando con la norma $l_2$. Utilice valores del parámetro de regularización $\\lambda$ en el rango [$10^7, 10^1$], variando si estima conveniente. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. (WARNING: Note que la lı́nea 3 y el primer argumento en la lı́nea 9\n",
    "son crı́ticos).\n",
    "\n",
    "> c) Ajuste un modelo lineal utilizando el método “*Lasso*”, es decir, regularizando con la norma $l_1$. Utilice valores del parámetro de regularización $\\lambda$ en el rango [$10^0,10^{-3}$]. Para obtener el código, modifique las lı́neas 7 y 9 del ejemplo anterior. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. ¿Es más efectivo Lasso para\n",
    "seleccionar atributos?\n",
    "\n",
    "> d) Escogiendo uno de los dos métodos regularizadores anteriores, especificando el porqué, construya un\n",
    "gráfico que muestre el error de entrenamiento y el error de pruebas como función del parámetro de\n",
    "regularización. Discuta lo que observa.\n",
    "\n",
    "> e) Estime el valor del parámetro de regularización en alguno de los modelos anteriores haciendo uso de\n",
    "la técnica validación cruzada con un número de folds igual a $K= 5$ y $K = 10$. Recuerde que para que la estimación sea razonable, en cada configuración (*fold*) deberá reajustar los pesos del modelo. Mida el error real del modelo sobre el conjunto de pruebas, compare y concluya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Análisis de audios como datos brutos\n",
    "\n",
    "Distintos tipos de datos han sido tratados en el área de Machine Learning, donde el análisis de estos y\n",
    "el manejo para poder dejarlos en una representación que se pueda entregar como entrada al algoritmo es\n",
    "crucial. El manejo sobre los datos brutos se denomina pre-procesamiento y existen distintos dependiento del\n",
    "tipo de datos y los distintos diminios de problemas, tales como imágenes, audios, texto.  \n",
    "En esta actividad se trabajará con datos de audios los cuales son directamente extraı́dos desde datos fuentes\n",
    "*.wav*, lo que corresponde a una señal de sonido en diferentes tiempos.\n",
    "\n",
    "imagen\n",
    "\n",
    "El *dataset* se denomina **Heartbeat Sounds** [3] y es presentado en la plataforma Kaggle a través del siguiente link... poner link ahi. Este dataset consta de grabaciones de sonidos de latidos cardı́acos normales y anormales, con distintas categorı́as para los latidos anormales. Para la tarea se trabajará con el *dataset A* presente en la data, el cual corresponde a datos generados desde la vı́a pública mediante la aplicación de Iphone iStethoscope Pro. El objetivo será el de clasificar cada sonido como latido cardı́aco normal o una de las las subcategorı́as de anormal (*Murmur, Extra Heart Sound, Artifact*), por lo que se trata de un problema de clasificación múltiple con 4 clases. Las distintas clasificaciones para los sonidos son explicadas en el sitio de Kaggle.\n",
    "\n",
    "Para leer y trabajar los archivos de extensión .wav se utilizará el siguiente código:\n",
    "```python\n",
    "from scipy.io import wavfile\n",
    "def clean_filename(fname, string):\n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':\n",
    "        file_name = string + file_name\n",
    "    return file_name\n",
    "SAMPLE_RATE = 44100\n",
    "def load_wav_file(name, path):\n",
    "    s, b = wavfile.read(path + name)\n",
    "    assert s == SAMPLE_RATE\n",
    "    return b\n",
    "```\n",
    "\n",
    "> a) Construya un dataframe con los datos a analizar. Describa el dataset y determine cuántos registros hay\n",
    "por clase.\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./heartbeat-sounds/set_a.csv')\n",
    "```\n",
    "\n",
    "> b) Lea los archivos *.wav* y transformelos en secuencias de tiempo. Realice un *padding* de ceros al final de cada secuencia para que todas queden representadas con la misma cantidad de elementos, explique la\n",
    "importancia de realizar este paso.\n",
    "```python\n",
    "def padd_zeros(array,length):\n",
    "    aux = np.zeros(length)\n",
    "    aux[:array.shape[0]] = array\n",
    "    return aux\n",
    "new_df =pd.DataFrame({'file_name' : df['fname'].apply(clean_filename,string='Aunlabelled')})\n",
    "new_df['time_series'] = new_df['file_name'].apply(load_wav_file, path='path/to/set_a/')\n",
    "new_df['len_series'] = new_df['time_series'].apply(len)\n",
    "new_df['time_series']=new_df['time_series'].apply(padd_zeros,length=max(new_df['len_series']))\n",
    "```\n",
    "> c) Manipule los datos y cambie las etiquetas de los audios por otras asignadas por un doctor experto [4],\n",
    "el cual afirma que estos cambios son requeridos. Vuelva a determinar cuántos registros hay por clase.\n",
    "Nótese que ahora son 3 clases ¿Explique la problemática de tener etiquetas mal asignadas en los datos?\n",
    "¿Un solo dato puede afectar esto?\n",
    "```python\n",
    "new_labels =...\n",
    "labels = ['artifact','normal/extrahls', 'murmur']\n",
    "new_df['target'] = [labels[i] for i in new_labels]\n",
    "```\n",
    "\n",
    "> d) Codifique las distintas clases a valores numéricos para que puedan ser trabajados por los algoritmos\n",
    "clasificadores.\n",
    "```python\n",
    "new_df[\"target\"] = new_df[\"target\"].astype('category')\n",
    "cat_columns = new_df.select_dtypes(['category']).columns\n",
    "new_df[cat_columns] = new_df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "```\n",
    "\n",
    "> e) Desordene los datos, evitando ası́ el orden en el que vienen la gran mayorı́a de las etiquetas. Cree la\n",
    "matriz que conforma a los datos en sus dimensiones sin preprocesar, es decir, cada ejemplo es una\n",
    "secuencia de amplitudes en el tiempo. ¿Las dimensiones de ésta indica que puede generar problemas?\n",
    "¿De qué tipo?\n",
    "```python\n",
    "new_df = new_df.sample(frac=1,random_state=44)\n",
    "X = np.stack(new_df['time_series'].values, axis=0)\n",
    "y = new_df.target.values\n",
    "X.shape\n",
    "```\n",
    "\n",
    "> f) Para pre procesar la secuencia en el tiempo realice una transformada de fourier discreta [5] para pasar\n",
    "los datos desde el dominio de tiempos al dominio de frecuencias presentes en la señal de sonido.\n",
    "```python\n",
    "X_fourier = np.abs(np.fft.fft(X))\n",
    "```\n",
    "\n",
    "> g) Para seguir con el pre procesamiento realice un muestreo representativo de los datos a través de una\n",
    "técnica de muestreo especializada en secuencias ¿En qué beneficia este paso? ¿Cómo podrı́a determinar\n",
    "si el muestro es representativo?\n",
    "\n",
    "```python\n",
    "from scipy import signal\n",
    "X_resampled = []\n",
    "for i in range(X_fourier.shape[0]):\n",
    "sequence = X_fourier[i,:].copy()\n",
    "resampled_sequence = signal.resample(sequence, 100000)\n",
    "X_resampled.append(resampled_sequence)\n",
    "X_resampled = np.array(X_resampled)\n",
    "X_resampled.shape\n",
    "```\n",
    "\n",
    "> h) Genere un conjunto de pruebas mediante la técnica hold-out validation para verificar la calidad de los\n",
    "```pyhon\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y,\n",
    "test_size=0.25, random_state=42)\n",
    "```\n",
    "> i) Realice un proceso de estandarizar los datos para ser trabajados adecuadamente. Recuerde que solo se\n",
    "debe ajustar (calcular media y desviación estándar) con el conjunto de entrenamiento.\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(with_mean=True, with_std=True)\n",
    "std.fit(X_train)\n",
    "X_train = std.transform(X_train)\n",
    "X_test = std.transform(X_test)\n",
    "```\n",
    "> j) Realice una reducción de dimensionalidad a través de la técnica PCA, para representar los datos en\n",
    "d = 2 dimensiones. Recuerde que solo se debe ajustar (encontrar las componentes principales) con el\n",
    "conjunto de entrenamiento. Visualice apropiadamente la proyección en 2 dimensiones.\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "d=2\n",
    "pca_model = PCA(n_components=d)\n",
    "pca_model.fit(X_train)\n",
    "X_pca_train = pca_model.transform(X_train)\n",
    "X_pca_test = pca_model.transform(X_test)\n",
    "```\n",
    "\n",
    "> k) Entrene un modelo de Regresión Logı́stica variando el parámetro de regularizacion C construyendo un\n",
    "gráfico resumen del error en función de este hiper-parámetro. Además entrene una Máquina de Soporte\n",
    "Vectorial (SVM) con kernel lineal, variando el hiper-parámetro de regularizacion *C* en el mismo rango\n",
    "que para la Regresión Logı́stica, construyendo el mismo gráfico resumen. Compare.\n",
    "```python\n",
    "Cs = [0.0001,0.01,0.1,1,10,100,1000]\n",
    "```\n",
    "\n",
    "> l) Quizás SVM?\n",
    "```python\n",
    "cs tambn\n",
    "```\n",
    "\n",
    "> m) Experimente con diferentes dimensiones d para la proyección de PCA con el propósito de obtener un\n",
    "modelo con menor error. Construya una tabla o gráfico resumen.\n",
    "\n",
    "> n) Realice otra reducción de dimensionalidad ahora a través de la técnica LDA, para representar los datos\n",
    "en d = 2 dimensiones. Recuerde que sólo se debe ajustar con el conjunto de entrenamiento, si se muestra\n",
    "un warning explique el porqué. Visualice apropiadamente la proyección en 2 dimensiones.\n",
    "```python\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "model_lda = LDA(n_components=2)\n",
    "model_lda.fit(X_train,y_train)\n",
    "X_pca_train = model_lda.transform(X_train)\n",
    "X_pca_test = model_lda.transform(X_test)\n",
    "```\n",
    "\n",
    "> o) Con el propósito de encontrar el mejor modelo vuelva a realizar el item h) con el i) en el nuevo espacio\n",
    "generado por la representación según las d dimensiones de la proyección LDA. Esta nueva representación\n",
    "¿mejora o empeora el desempeño? Explique.\n",
    "\n",
    "> p) Intente mejorar el desempeño de los algoritmos ya entrenados. Diseñe ahora sus propias cracterı́sticas\n",
    "(feature crafting) a partir de los datos brutos (secuencia de amplitudes), puede inspirarse en otros\n",
    "trabajos [6] [7] si desea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 3. Análisis de emociones en *tweets*\n",
    "\n",
    "\n",
    "Pharagraph vector (señalar ideas)\n",
    "\n",
    "ver la predicción jerárquica (señalarles como ideas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
