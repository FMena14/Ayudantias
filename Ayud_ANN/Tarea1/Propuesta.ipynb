{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Y1tHj3DNqhX"
   },
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 1 - Redes Neuronales y *Deep Learning* </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "\n",
    "* Entrenamiento de redes *Feed-Forward* vı́a GD y variantes (SGD, mini-*batches*), *momentum*, regularización y tasa de aprendizaje adaptiva.\n",
    "* Rol de capas ocultas y mayor profundidad (*Deep Learning*).\n",
    "* Diseño y entrenamiento de Redes Neuronales Convolucionales (CNNs).\n",
    "* Aplicaciones de las Redes Neuronales Convolucionales\n",
    "* Técnicas de regularización: *Dropout* y *Batch Normalization* \n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2-3 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y discusión: 26 de Abril.\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea1-INF395-I-2019]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "#### Paquetes instalación\n",
    "\n",
    "Para poder trabajar en el curso se necesitará instalar librerías para Python, por lo que se recomienda instalarlas a través de anaconda (para Windows y sistemas Unix) en un entorno virtual, donde podrán elegir su versión de Python. Se instalarán librerías como sklearn, una librería simple y de facil acceso para data science, keras en su versión con GPU (para cálculo acelerado a través de la tarjeta gráfica), además de que ésta utiliza como backend TensorFlow o Theano, por lo que habrá que instalar alguno de éstos, además de las librerías básicas de computer science como *numpy, matplotlib, pandas,* además de claramente *jupyter*.\n",
    "\n",
    "* Descargar anacona\n",
    "* Luego de instalar Anaconda y tenerla en el path de su computador crear un entorno virtual:\n",
    "```\n",
    "conda create -n redesneuronales python=version\n",
    "```\n",
    "con version, la version de Python que desea utilizar. Si está en Windows, se recomienda Python 3 debido a dependencias con una de las librerías a utilizar.\n",
    "\n",
    "* Acceder al ambiente creado\n",
    "```\n",
    "source activate redesneuronales\n",
    "```\n",
    "\n",
    "* Instalar los paquetes a utilizar\n",
    "```\n",
    "conda install jupyter sklearn numpy pandas matplotlib keras-gpu tensorflow-gpu\n",
    "```\n",
    "O vía *pip*\n",
    "```\n",
    "pip install jupyter sklearn numpy pandas matplotlib tensorflow-gpu keras\n",
    "```\n",
    "\n",
    "*  Para salir del entorno\n",
    "```\n",
    "source deactivate redesneuronales\n",
    "```\n",
    "\n",
    "No olvide revisar las dependencias de las versiones de librerías, por ejemplo la de tensorflow-gpu: https://www.tensorflow.org/install/source#tested_source_configurations\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Red Neuronal *Feed Forward* para Detectar Exoplanetas  \n",
    "[2.](#segundo) *Deep Networks*  \n",
    "[3.](#tercero) Redes Convolucionales en Imágenes  \n",
    "[4.](#cuarto) CNN *vs* RNN Prediciendo el Ozono Atmosférico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ"
   },
   "source": [
    "#### <a id=\"primero\"></a>\n",
    "## 1. Red Neuronal *Feed Forward* para Detectar Exoplanetas\n",
    "---\n",
    "\n",
    "Las Redes Neuronales Artificiales (ANN) son un tipo de modelo de aprendizaje que, con el suficiente número de capas, debiera poder aproximar cualquier función. Hoy en día se han aplicado a numerosos problemas, ya que tienen la ventaja de ser bastante dinámicas en su construcción y poder ser entrenadas con unicamente *backpropagation*, obteniendo un buen desempeño. Los modelos de aprendizaje son aplicados a diferentes ámbitos en donde en algunos casos automatizan extensivos procesos manuales de expertos, como lo que veremos a continuación.\n",
    "\n",
    "<img src=\"https://www.cfa.harvard.edu/~avanderb/tutorial/HAT-P-3b.gif\" title=\"YOLO\" width=\"30%\"/>\n",
    "\n",
    "En esta sección trabajaremos con un dataset de astronomía, **Kepler KOI** [[1]](#refs), en el cual podrán experimentar con la detección de exoplanetas a través de *features* extraídas de las curvas de luz (tránsito de los planetas sobre su estrella madre) y metadatos de la observación (planeta, estrella y curvas de luz). Para más información sobre los metadatos visite el siguiente __[link](https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html)__. La tarea es determinar si un posible candidato a exoplaneta (en base a una previa identificación de eventos que sobrepasan un cierto *treshold*) corresponde efectivamente a un exoplaneta o no.\n",
    "\n",
    "---\n",
    "En primer lugar cargue todos los datos trabajados por [[2]](#refs), los cuales se encuentran adjuntados con el enunciado. Además separe en entrenamiento y pruebas.\n",
    "```python\n",
    "import pandas  as pd\n",
    "df_sets = pd.read_csv(\"./koi_sets_unb.csv\")\n",
    "mask_train = (df_sets[\"Set\"] == \"Train\").values\n",
    "mask_test = (df_sets[\"Set\"] == \"Test\").values\n",
    "df_labels = pd.read_csv(\"./koi_labels.csv\")\n",
    "df_X = pd.read_csv(\"./koi_light_curves_X.csv\")\n",
    "df_labels_train = df_labels[mask_train]\n",
    "df_labels_test = df_labels[mask_test]\n",
    "df_X_train = df_X[mask_train]\n",
    "df_X_test = df_X[mask_test]\n",
    "```\n",
    "\n",
    "A continuación cree las matrices para entrenar su modelo neuronal, la etiqueta binaria (0 o 1) y la matriz numérica de entrada, imputando la mediana sobre los valores nulos.\n",
    "```python\n",
    "y_train = ((df_labels_train[\"NExScI Disposition\"]==\"CONFIRMED\")*1).values\n",
    "y_test = ((df_labels_test[\"NExScI Disposition\"]==\"CONFIRMED\")*1).values\n",
    "df_X_train = df_X_train.reset_index(drop=True)\n",
    "df_X_test = df_X_test.reset_index(drop=True)\n",
    "df_X_train.fillna(df_X_train.median(), inplace=True)\n",
    "df_X_test.fillna(df_X_test.median(), inplace=True)\n",
    "X_train = df_X_train.values[:,1:]\n",
    "X_test = df_X_test.values[:,1:]\n",
    "```\n",
    "\n",
    "> a) Explore los datos trabajados, ya sea con estadísticos simples o con gráficos como histogramas y/o boxplots. Comente sobre el problema enfrentado, es decir, la tarea de transformar un vector $X$ en un valor categórico (0 o 1).\n",
    "```python\n",
    "columns_names = df_X_train.columns[1:]\n",
    "print(columns_names)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "df_X_train.describe()\n",
    "```\n",
    "\n",
    "> b) Escale los datos para ser trabajados por el modelo de aprendizaje, indique la importancia de éste paso. Además cree un conjunto de validación extrayendo un cierto porcentaje del conjunto de entrenamiento, por ejemplo el 20% manteniendo el desbalanceo de clases (*split* stratificado).\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = ...\n",
    "X_test_scaled =  scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "> c) Muestre en un gráfico la función objetivo (*cross entropy*) para el conjunto de entrenamiento y de validación *vs* número de *epochs* de entrenamiento, para una red *feedforward* de 3 capas, con 256 unidades ocultas y función de activación sigmoidal. Entrene la red usando gradiente descendente estocástico con tasa de aprendizaje (*learning rate*) 0.01 y 100 *epochs* de entrenamiento. Comente. Si observara divergencia durante el entrenamiento, determine si esto ocurre para cada repetición del experimento. Compare el efecto de variar la función de activación a **ReLU** ¿Qué observa en la convergencia del modelo?\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"sigmoid\")) #this should be mantained\n",
    "model.compile(optimizer=SGD(lr=0.01),loss='binary_crossentropy')\n",
    "hist = model.fit(X_train_scaled, y_train, epochs=100, verbose=1, validation_data=(X_val_scaled, y_val))\n",
    "```\n",
    "> Finalmente compare a través de una métrica de desempeño sobre el conjunto de pruebas, en este caso como trabajamos un problema desbalanceado, mida *f1 score weighted*, comente sobre esta decisión ¿Es esperable la diferencia entre relu y sigmoidal en base a los gráficos realizados?\n",
    "```python\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,model_sigmoid.predict_classes(X_test_scaled),average='weighted')\n",
    "f1_score(y_test,model_relu.predict_classes(X_test_scaled),average='weighted')\n",
    "```\n",
    "\n",
    "> d) Repita c) variando la tasa de aprendizaje (*learning rate*) en un rango sensible. Comente. Si observa divergencia durante el entrenamiento, determine si esto ocurre para cada repetición del experimento o para alguna de las dos funciones de activación experimentadas.\n",
    "```python\n",
    "import numpy as np\n",
    "n_lr = 20\n",
    "lear_rate = np.linspace(0,1,n_lr)\n",
    "```\n",
    "\n",
    "> e) Entrene los modelos considerados en c) usando *progressive decay*. Compare y comente.\n",
    "```python\n",
    "n_decay = 10\n",
    "lear_decay = np.logspace(-6,0,n_decay)\n",
    "sgd = SGD(lr=0.2, decay=1e-6)\n",
    "```\n",
    "\n",
    "> f) Entrene los modelos considerados en c) usando *momentum* [[3]](#refs). Experimente usando *momentum* clásico y *momentum* de Nesterov. ¿Observa un mejor resultado final? ¿Observa una mayor velocidad de convergencia sobre el conjunto de entrenamiento? ¿Sobre el conjunto de validación?\n",
    "```python\n",
    "split_space = 21\n",
    "momentum = np.linspace(0,1,split_space)\n",
    "sgd = SGD(lr=0.01,momentum=0.9,nesterov=False)\n",
    "```\n",
    "\n",
    "> g) Vuelva a entrenar los modelos considerados en c) utilizando SGD en mini-*batches*. Experimente con diferentes tamaños del *batch*. Comente sobre eficacia de convergencia *vs* eficiencia computacional.\n",
    "```python\n",
    "n_batches = 21\n",
    "batch_sizes = np.round(np.linspace(1,X_train_scaled.shape[0],n_batches))\n",
    "model.fit(X_train_scaled,y_train,batch_size=50,epochs=100,validation_data=(X_val_scaled, y_val))\n",
    "```\n",
    "\n",
    "> h) Entrene los modelos obtenidos en c) utilizando estrategias modernas para adaptar la tasa de aprendizaje. Compare los desempeños de *adagrad, adadelta, RMSprop* y *adam*, ofrecidos en __[keras optimizer](https://keras.io/optimizers/)__. ¿Se observa en algún caso un mejor resultado final? ¿Se observa en algún caso una mayor velocidad de convergencia sobre el dataset de entrenamiento? ¿Sobre el dataset de validación?\n",
    "```python\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "model.compile(optimizer=moptimizer)\n",
    "model.fit(X_train_scaled,y_train,batch_size=bs,epochs=100,validation_data=(X_val_scaled, y_val))\n",
    "```\n",
    "\n",
    "> i) Entrene los modelos obtenidos en c) utilizando regularizadores clásicos $l_1$ y $l_2$ (*weight decay*). Compare los desempeños de prueba obtenidos antes y después de regularizar. Experimente con distintos valores del parámetro de regularización y comente. Además evalúe el efecto de regularizar solo la primera capa *vs* la segunda, comente. *Recuerde que la regularización se debe añadir a cada capa separadamente*\n",
    "```python\n",
    "from keras.layers import Activation\n",
    "from keras.regularizers import l1,l2\n",
    "model = Sequential()\n",
    "model.add(Dense(256,input_dim=X_train_scaled.shape[1],kernel_initializer='uniform',kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('sigmoid')) #and relu\n",
    "model.add(Dense(1, kernel_initializer='uniform',kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "```\n",
    "\n",
    "> j) Elija uno de los dos modelos definidos en c) y experimente con modificar la función objetivo, que hasta ahora se lo hemos dejado a keras definir la típica *binary cross entropy*, en pos de algún objetivo que decida plantearse, por ejemplo aumentar el tiempo de convergencia (reducir más rápida la función objetivo), obtener mejor desempeño en *f1 score* u algún otro.  \n",
    "*Se dejan algunos ejemplos*\n",
    "    1. Cross entropy + Focal loss [[4]](#refs)\n",
    "    2. Cross entropy + Min entropy\n",
    "    3. Cross entropy + Max entropy\n",
    "    4. Kullback Leibler (KL) ó Jensen Shannon (JS) divergence [[5]](#refs)\n",
    "    5. Weighted Cross entropy\n",
    "```python\n",
    "from keras import backend as K\n",
    "def custom_loss(value): #ejemplo\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = K.clip(y_true, K.epsilon(), 1) \n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "        return K.sum(y_true * K.log(y_true / y_pred), axis=-1) #KL-divergence\n",
    "        ...#return value*K.mean(K.square(y_pred - y_true), axis=-1) #MSE\n",
    "    return loss\n",
    "model.compile(loss=custom_loss(1),optimizer=opt)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFtCUBp9Nqhb"
   },
   "source": [
    "<a id=\"segundo\"></a>\n",
    "\n",
    "## 2. Deep Networks\n",
    "---\n",
    "Las *deep network*, o lo que hoy en día se conoce como *deep learning*, hace referencia a modelos de redes neuronales estructurados con muchas capas, es decir, el cómputo de la función final es la composición una gran cantidad de funciones ( $f^{(n)} = f^{(n-1)} \\circ f^{(n-2)} \\circ \\cdots \\circ f^{(2)} \\circ f^{(1)} $ con $n \\gg 0$ ).  \n",
    "Este tipo de redes neuronales tiene una gran cantidad de parámetros, creciendo exponencialmente por capa con las redes *feed forward*, siendo bastante dificiles de entrenar comparadas con una red poco profunda, esto es debido a que requieren una gran cantidad de datos para ajustar correctamente todos esos parámetros. Pero entonces ¿Cuál es el beneficio que tienen este tipo de redes? ¿Qué ganancias trae el añadir capas a una arquitectura de una red neuronal?   Y luego, lo más importante ¿Cómo entrenamos este tipo de redes?\n",
    "\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz36.png\" title=\"Title text\" width=\"80%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "\n",
    "En esta sección se estudiará la complejidad de entrenar redes neuronales profundas, mediante la visualización de los gradientes de los pesos en cada capa, el cómo varía mientras se hace el *backpropagation* hacia las primeras capas de la red. Además del efecto del cambio de funciones de activación.\n",
    "\n",
    "---\n",
    "\n",
    "Volveremos a trabajar con el dataset de exoplanetas de la [sección 1](#primero). Cárguelo y genere las matrices a trabajar.\n",
    "\n",
    "> a) En esta primera instancia se trabajará con una red *shallow* (poco profunda) con una gran cantidad de neuronas situadas en una capa, inicializada con pesos uniforme. Visualice el gradiente de la función de pérdida (*loss*) para el conjunto de entrenamiento (promedio del gradiente de cada dato) respecto a los pesos en las distintas capas, para esto se le pedirá el cálculo del gradiente para una capa mediante la función de *gradients* (__[link](https://www.tensorflow.org/api_docs/python/tf/keras/backend/gradients)__) en el *backend* de Keras, otra opción es a través de un __[monitor](https://keras.io/callbacks/#tensorboard)__. Deberá generar un **histograma** para todos los pesos de cada capa antes y despues del entrenamiento con 50 *epochs*. Comente.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(1280, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation='sigmoid'))\n",
    "compilar\n",
    "- ###calculate gradients\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "loss = keras.losses.mean_squared_error(model.output,y_train_scaled)\n",
    "listOfVariableTensors = model.trainable_weights \n",
    "gradients = K.gradients(loss, listOfVariableTensors) #We can now calculate the gradients.\n",
    "sess = K.get_session()\n",
    "evaluated_gradients = sess.run(gradients,feed_dict={model.input:X_train_scaled.values})\n",
    "evaluated_gradients = [gradient/len(y_train) for gradient in evaluated_gradients]\n",
    "```\n",
    "\n",
    "> b) Vuelva a generar los histogramas para los gradientes de los pesos de cada capa antes y después del entrenamiento pero ahora entrenando una red con los mimos pesos distribuidos a través de muchas más capas (red profunda de 6 capas), 5 capas escondidas y 1 de salida. Utilice el inicializador de pesos *uniform* el cual inicializa mediante una distribución uniforme entre $-1/\\sqrt{N}$ y $1/\\sqrt{N}$ para cada capa, con $N$ el número de neuronas de la capa anterior. Por simplicidad visualice las 3-4 primeras capas de la red. Comente si observa el efecto del *gradiente desvaneciente* antes y/o después de entrenar. ¿Qué sucede con la *loss*? ¿El modelo logra aprender?\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation='sigmoid'))\n",
    "sgd = SGD(lr=0.01)\n",
    "compilar\n",
    "```\n",
    "\n",
    "> c) Vuelva a generar los histogramas para los gradientes de los pesos de cada capa antes y después del entrenamiento, pero ahora entrenando la red profunda con el inicializador de Glorot [[6]](#refs), es decir, una distribución uniforme entre -$\\sqrt{6/(N_{in}+N_{out})}$  y $\\sqrt{6/(N_{in}+N_{out})}$ . Por simplicidad visualice las 3-4 primeras capas de la red. Comente si el efecto del *gradiente desvaneciente* se amortigua antes y/o después de entrenar. ¿Qué sucede ahora con la *loss*? ¿El modelo logra aprender?\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "sgd = SGD(lr=0.01)\n",
    "compilar\n",
    "```\n",
    "\n",
    "> d) Vuelva a repetir la experimentación ahora cambiando la función de activación por ReLU, es decir, deberá visualizar los gradientes de los pesos de cada capa antes y después del entrenamiento, con inicialización *uniform* y comparar con la inicialización de He [[7]](#refs), es decir, una distribución uniforme entre -$\\sqrt{6/N_{in}}$ y $\\sqrt{6/N_{in}} $. Comente si ocurre el mismo fenómeno anterior (para función sigmoidal) sobre el efecto del *gradiente desvaneciente* para la función ReLU. Explique la importancia de la inicialización de los pesos dependiendo de la arquitectura. \n",
    "```python\n",
    "...\n",
    "model.add(Dense(nh, kernel_initializer='uniform',activation='relu')) #uniform\n",
    "...\n",
    "or\n",
    "...\n",
    "model.add(Dense(nh, kernel_initializer='he_uniform',activation='relu')) #he\n",
    "...\n",
    "```\n",
    "\n",
    "> e) Experimente con la utilización de una función activación auxiliar (debido a que aproxima) a '**ReLU**' y que es continua derivable (**softplus**) ¿Cuál es el beneficio de ésta con respecto ReLU? Comente.\n",
    "```python\n",
    "...\n",
    "model.add(Dense(nh, kernel_initializer='he_uniform',activation='softplus')) #softplus\n",
    "...\n",
    "```\n",
    "\n",
    "> f) ¿Qué es lo que sucede con la red más profunda? ¿El modelo logra convergencia en su entrenamiento? Vuelva a experimentar con variar la función de activación con el propósito de lograr un buen aprendizaje y generalización del modelo en base a la *loss*. Experimente con la familia ReLU (LeakyReLU, PReLU, ELU, ThresholdedReLU), algunas en el __[link](https://keras.io/layers/advanced-activations/)__. ¿Con cuál se aprende más rápido en términos de la *loss*? Además monitoree neuronas muertas (*dying neuron*) a través de los valores de la activación (por ejemplo ReLU con valor 0 no genera gradiente) con un histograma a lo largo del entrenamiento.  \n",
    "*Hint: ésto último se puede visualizar con lo de la pregunta b), __[TensorBoard](https://keras.io/callbacks/#tensorboard)__*.\n",
    "```python\n",
    "from keras.layers import LeakyReLU, PReLU, ELU, ThresholdedReLU\n",
    "LeakyReLU(alpha=0.3)\n",
    "PReLU(alpha_initializer='zeros')\n",
    "ELU(alpha=1.0)\n",
    "ThresholdedReLU(theta=1.0)\n",
    "...\n",
    "model.add(Dense(nh, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "...\n",
    "```\n",
    "\n",
    "> g) Ahora, sin variar la profundidad de la red definida en b), se pedirá que experimente con otra variación que podría resultar provechoso para la generalización y aprendizaje del modelo, la técnica de *Dropout* [[8]](#refs) y la técnica de *Batch Normalization*[[9]](#refs). Decida si colocarlas en todas las capas o en algunas. Comente sobre el efecto esperado y el observado.\n",
    "```python\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "...\n",
    "model.add(Dense(nh, activation=act, kernel_initializer=init))\n",
    "model.add(Dropout(dropout_rate))\n",
    "...\n",
    "...\n",
    "model.add(Dense(nh, activation=act, kernel_initializer=init))\n",
    "model.add(BatchNormalization())\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 3. Redes Convolucionales en Imágenes\n",
    "---\n",
    "\n",
    "En esta sección trabajaremos con un *dataset* bastante conocido y utilizado por la comunidad para experimentar reconocimiento de objetos en imágenes: CIFAR-10. Se trata de un conjunto de 60000 imágenes RGB de 32 × 32 pixeles que contiene 10 clases de objetos y 6000 ejemplos por clase. La versión utilizada se le atribuye a *A. Krizhevsky, V. Nair* y *G. Hinton*  [[10]](#refs), viene separada en 50000 ejemplos de entrenamiento y 10000 casos de prueba que fueron obtenidos seleccionando 1000 imágenes aleatorias de cada clase. Cabe destacar que las clases son mutuamente excluyentes y corresponden a las siguientes categorı́as: \n",
    "\n",
    "<img src=\"https://cv-tricks.com/wp-content/uploads/2017/03/alexnet_small.png.pagespeed.ce.j1fiN1R4Hv.png\" title=\"YOLO\" width=\"70%\" style=\"float: left;\"/>\n",
    "\n",
    "* Avión\n",
    "* Automóvil\n",
    "* Pájaro\n",
    "* Gato\n",
    "* Ciervo\n",
    "* Perro\n",
    "* Rana\n",
    "* Caballo\n",
    "* Barco\n",
    "* Camión\n",
    "\n",
    "\n",
    "Para esta tarea se experimentará con redes convolucionales, conocidas como CNNs ó ConvNets.  \n",
    "**Nota:** Para esta actividad es bastante aconsejable entrenar las redes usando una GPU, ya que de otro modo los tiempos de entrenamiento serán largos. \n",
    "\n",
    "\n",
    "**Recuerde que si encuentra cosas ventajosas en alguna pregunta, puede y debería seguir utilizandolas en las siguientes preguntas**\n",
    "\n",
    "---\n",
    "\n",
    "Cargue todos los datos de entrenamiento y pruebas del problema CIFAR generando como salida además de generar un conjunto de validación del conjunto de entrenamiento y no debe superar 5000 imágenes.\n",
    "```python\n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  \n",
    "import numpy as np   \n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "... #create validation\n",
    "```\n",
    "\n",
    "> a) Visualice los datos que trabajaremos e intentaremos detectar en esta sección. ¿Qué dimensiones tienen las imágenes trabajadas? ¿Existen patrones similares entre los objetos de una misma clase? ¿Entre objetos de distintas clases?.\n",
    "```python\n",
    "idx_dato = [np.random.choice(np.where(y_train==i)[0]) for i in range(10)] #sample from each class\n",
    "f,axx = plt.subplots(2,5,figsize=(10,5))\n",
    "for i, dato in enumerate(idx_dato):\n",
    "    axx[int(i/5),i%5].imshow(x_train[dato])\n",
    "    axx[int(i/5),i%5].axis('off')\n",
    "    axx[int(i/5),i%5].set_title(label_names[i])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "> b) Prepare los subconjuntos de entrenamiento, validación y pruebas para ser entregados al modelo. Para ésto divida la intensidad original de pixel en cada canal por 255. Es importante notar que si desea trabajar con el orden de las dimensiones denominado ’th’ (por defecto para *Theano*) deberá realizar la transposición correspondiente para dejar el canal en donde corresponda. Finalmente, genere una representación adecuada de las salidas deseadas de la red.\n",
    "```python\n",
    "import keras\n",
    "..#x_train = x_train.transpose([0, 3, 1, 2]) #if 'th' dim-ordering is used\n",
    "..#x_test= x_test.transpose([0, 3, 1, 2]) \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "Xnorm_train = x_train.astype('float32')/255\n",
    "Xnorm_val = x_val.astype('float32')/255\n",
    "Xnorm_test = x_test.astype('float32')/255\n",
    "```\n",
    "\n",
    "> c) Defina una CNN simple con arquitectura $C \\times P \\times C \\times P \\times F \\times F$. Para ambas capas convolucionales utilice 64 filtros de $3 \\times 3$ y funciones de activación ReLU. Para las capas de *pooling* utilice filtros de $2 \\times 2$ con *stride* 2. Para la capa MLP escondida use 512 neuronas. Genere un esquema lo más compacto posible que muestre los cambios de forma (dimensionalidad) que experimenta un patrón de entrada a medida que se ejecuta un *forward-pass* y el número de parámetros de cada capa.\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=Xnorm_train.shape[1:],activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "> d) Entrene la CNN definida en **c)** utilizando SGD. En este dataset, una tasa de aprendizaje “segura” es $\\eta = 10^{-4}$ o inferior con una tasa de decaimiento, pero durante las primeras *epochs* el entrenamiento resulta demasiado lento. Para resolver el problema compare el entrenar con un optimizador adaptativo como es **RMSProp** con parámetros similares. Construya un gráfico que muestre los errores de entrenamiento, validación y pruebas como función del número de “epochs”, entrene con 25 *epochs*.\n",
    "```python\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "opt = SGD(lr=1e-4,decay=1e-6)\n",
    "model.compile( ... )\n",
    "model.fit(Xnorm_train, y_train,batch_size=batch_size,epochs=epochs, validation_data=(Xnorm_val,y_val))\n",
    "opt = rmsprop(lr=1e-4, decay=1e-6)\n",
    "model.compile( ... )\n",
    "model.fit(Xnorm_train, y_train,batch_size=batch_size,epochs=epochs, validation_data=(Xnorm_val, y_val))\n",
    "```\n",
    "\n",
    "> e) Ahora bien, para mejorar los resultados encontrados deberá aumentar o reducir el número de capas, dependiendo de qué dice su intuición. Deberá elegir sobre dónde aumentar el número de capas, la fase convolucional y/o la fase *feed forward*, no olvide que al aumentar el número de capas (como en la sección 2) conlleva ciertas consecuencias, lo más importante el *overfitting*, vea cómo reducir ésto.\n",
    "\n",
    "> f) Ahora deberá experimentar con variar (aumentar o reducir) el número de filtros de cada capa convolucional. ¿Qué podría ser mas aconsejable? ¿Mantener el tamaño de los filtros usados en cada capa? ¿Aumentar los filtros a través de las capas? ¿Reducir los filtros a través de éstas?\n",
    "\n",
    "> g) Dentro de lo experimentado no se ha hablado sobre el tamaño de los filtros (de convolución), siendo un factor bastante importante a decidir dependiendo de los datos de entrada. Evalúe el efecto de modificar éstos tamaño de filtros reportando la sensibilidad de error de pruebas a estos cambios. Decida sobre una opción, aumentar o reducir y verifique si se cumple lo que espera.\n",
    "```python\n",
    "...\n",
    "model.add(Conv2D(64, (nc, nc), padding='same', input_shape=Xnorm_train.shape[1:],activation='relu'))\n",
    "...\n",
    "```\n",
    "\n",
    "> h) Se ha sugerido que la práctica bastante habitual de continuar una capa convolucional con una capa de *pooling* puede generar una reducción prematura de las dimensiones del patrón de entrada. Experimente con una arquitectura del tipo $C \\times P \\times C \\times P \\times F \\times F$ versus  $C \\times C \\times P \\times C \\times C \\times P \\times F \\times F$. Use 32 filtros para la primera capa convolucional y 64 para la segunda.  Como resultado final de esta actividad, al igual que las otras, gráfique los errores de entrenamiento, validación y pruebas como función del número de “epochs” (fijando el máximo en un número razonable como T = 25).\n",
    "> **Hint:** con esta nueva arquitectura debiese superar el 70% de accuracy (de validación/test), pero la arquitectura es más sensible a overfitting por lo que podrı́a ser conveniente agregar un regularizador ¿Dónde? ¿Qué tan potente?\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=Xnorm_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "dropout?\n",
    "...\n",
    "```\n",
    "\n",
    "> i) Algunos investigadores, han propuesto que las capas de *pooling* se pueden reemplazar por capas convoluciones con *stride* 2. ¿Se reduce dimensionalidad de este modo? Compruébelo verificando los cambios de forma (dimensionalidad) que experimenta un patrón de entrada a medida que se ejecuta un *forward-pass*. Entrene la red resultante con el método que prefiera, gráficando los errores de entrenamiento, validación y pruebas como función del número de “epochs” (fijando el máximo en un número razonable como T = 25).\n",
    "```python\n",
    "...\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same',activation='linear'))\n",
    "...\n",
    "```\n",
    "\n",
    "> j) Una forma interesante de regularizar modelos entrenados para visión artificial consiste en “aumentar” el número de ejemplos de entrenamiento usando transformaciones sencillas como: rotaciones, corrimientos y reflexiones, tanto horizontales como verticales. Explique por qué este procedimiento podrı́a ayudar a mejorar el modelo y el por qué las etiquetas no cambian al aplicar estas operaciones. Evalúe experimentalmente la conveniencia de incorporarlo.\n",
    "```python\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images (degrees, 0 to 180)\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of width)\n",
    "    height_shift_range=0.1, # randomly shift images vertically (fraction of height)\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False) # randomly flip images\n",
    "datagen.fit(Xnorm_train)\n",
    "model.fit_generator(datagen.flow(Xnorm_train, y_train,batch_size=batch_size),steps_per_epoch=Xnorm_train.shape[0]// batch_size, epochs=epochs,validation_data=(Xnorm_val, y_val))\n",
    "```\n",
    "\n",
    "> k) Ahora se experimentará con el concepto de *transfer learning* [[11]](#refs), el cual consta en transferir conocimiento de un dominio fuente (*source domain*) a un dominio objetivo (*target domain*). En redes neuronales existen muchas representaciones de esto, en común consta en pre inicializar los pesos de la red de alguna manera que no sea con distribuciones de manera aleatoria (fine tunning). También está lo que es utilizar una representación generada a través de otra red entrenada con muchos datos, esto es tomar la red y \"congelar\" sus primeras capas para tomar esta representación y no entrenar esos pesos. Para ésto se utilziara VGG16 [[12]](#refs), una red entrenada con millones de imágenes y proporcionada a través de la interfaz de *keras*. Visualice el modelo y sus 23 capas.  Para esta instancia se utilizará todo lo aprendido por las capas convolucionales, es decir, se eliminan las capas densas del modelo y se agregan unas nuevas a ser entrenadas desde cero.  \n",
    "*Recuerde normalizar los datos de la manera en que fue entrenado VGG* ¿Cuál es éste proceso?\n",
    "```python\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "X_train_vgg = preprocess_input(x_train.astype('float32'))\n",
    "X_test_vgg = preprocess_input(x_test.astype('float32'))\n",
    "input_tensor=Input(shape=X_train_vgg.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor ) # LOAD PRETRAINED MODEL \n",
    "features_train = modelVGG.predict(X_train_vgg)\n",
    "features_test = modelVGG.predict(X_test_vgg)\n",
    "modelVGG.summary()\n",
    "```\n",
    "\n",
    "> l) Entrene esta red agregando una capa densa de 512 neuronas seguido de un dropout de 0.5, finalmente es necesario agregar la capa de clasificación para las 10 clases. Utilice la misma configuración del optimizador para que las comparaciones sean válidas. Entrene unicamente por 15 *epochs* y grafique las curvas de entrenamiento con respecto al modelo definido en c) y la mejor encontrada ¿Qué sucede? Comente.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "...#clasification\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,epochs=epochs_, batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
    "```\n",
    "\n",
    "> m) Agregue una capa de normalización (*Batch Normalization* [[9]](#refs)) de las activaciones en las capas densas, esto es, restar por la media del batch y dividir por la desviación estándar con unos parámetros aprendibles y *dropout*[[8]]](#refs). Vuelva a entrenar el modelo con la misma configuración. Comente lo observado y compare las curvas de convergencia con los modelos anteriores ¿Por qué esto mejora a lo presentado en l)? ¿Qué beneficio tiene resolver un problema con una red pre-entrenada?\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(value))\n",
    "...#clasification\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,epochs=epochs_, batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
    "```\n",
    "\n",
    "> n) Genere $T$ nuevas etiquetas para el dataset de CIFAR en base a las etiquetas de éstas, pero que sean \"paralelas\", es decir, un objeto/imagen puede tener una etiqueta de las posibles en CIFAR y una de las nuevas que usted genere, ésto se denomina **Multi-task**[[13]](#refs). Por ejemplo una nueva *task* podría ser la identificar entre animales u objetos (de manera binaria, 0 y 1) en los datos de CIFAR, ésto debe ser unicamente extraído a través de las etiquetas de CIFAR. Defina la sección compartida de la red, que se compartirá para aprender las $T+1$ tareas, que tome como entrada las imágenes de CIFAR, ya sean los pixeles o la representación de *VGG* y genere como salida una representación intermedia (*hidden*) que servirá después para aprender cada la probabilidad (*softmax* o *sigmoid*) de cada *task*.\n",
    "```python\n",
    "...# create your new tasks\n",
    "shared_model = Sequential()\n",
    "...\n",
    "shared_model.add(Dense(n_hidd,activation='relu'))\n",
    "shared_model.summary() \n",
    "```\n",
    "\n",
    "> o) Defina y entrene el modelo multi-task que prediga las $T$ nuevas *task* que definió en la pregunta anterior más la clasificación sobre CIFAR, *task 1*. Grafique las $T+1$ funciones objetivos que se optimizan en paralelo, comente. Verifique si el uso de las nuevas $T$ *task* auxiliares ayudan a regularizar a la red sobre la tarea principal, la clasificación sobre las etiquetas de CIFAR (*task 1*).   \n",
    "*Como ayuda se entrega que como la task1 es la clasificación de CIFAR la loss1 debiera ser 'categorical_crossentropy'*\n",
    "```python\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "input_tasks = Input(shape = X.shape[1:])\n",
    "shared = shared_model(input_tasks) #shared_part\n",
    "class_cifar = Dense(10,activation='softmax')(shared)\n",
    "task2 = Dense(??)(shared)\n",
    "task3 = Dense(??)(shared)\n",
    "...\n",
    "multitask_model = Model(inputs=input_tasks, outputs = [class_cifar, task2, task3, ...])\n",
    "multitask_model.compile(loss = [loss1,loss2,loss3,...],optimizer=optimizer_, metrics=[\"acc\"])\n",
    "multitask_model.fit(X, [Y_cifar,Y_task2,Y_task3,...],epochs=25,batch_size=BATCH_SIZE,verbose=1)\n",
    "```\n",
    "\n",
    "> Una forma cómoda de visualizar el modelo es a través de *plot model* de *keras*.\n",
    "```python\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot,plot_model\n",
    "SVG(model_to_dot(multitask_model).create(prog='dot', format='svg'))\n",
    "```\n",
    "\n",
    "> p) Elija una de las redes entrenadas en esta sección (preferentemente una con buen desempeño) y determine las predicciones menos insegura de la red, en base a algún criterio (por ejemplo la predicciones con mayor entropía en su probabilidad), también ver en qué objetos se equivoca (los más probables) por ejemplo la red podría a tender a confundir camiones con autos. Conjeture el motivo de tal confusión.\n",
    "\n",
    "> q) Elija una de las redes entrenadas (preferentemente una con buen desempeño) y visualice los pesos correspondientes a los filtros de la primera capa convolucional. Visualice además el efecto del filtro sobre algunas imágenes de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "## 4. CNN *vs* RNN Prediciendo el Ozono Atmosférico\n",
    "---\n",
    "\n",
    "> Entendimiento del problema lectura de dataset de predecir el siguinete valor en ozono\n",
    "\n",
    "> Solo con input: Ozono (1-D)\n",
    "\n",
    "> a) crear su propia estructura de dataset (seleccionando el T) -- CNN 1d vs Simple RNN\n",
    "> b) que pasa si el lag se agrega como features y T=1 --- CNN 1d vs Simple RNN\n",
    "> c) variar el T de la a) -- mismo\n",
    "> d) time folding (T!= 1 y features != 1), -- Conv 2d vs simple RNN\n",
    "\n",
    "> Agregar nuevos input: Otras mediciones (series de tiempo N-D)\n",
    "\n",
    "> a) seleccionar T y experimentar -- CNN 1d vs CNN 2d vs Simple RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YAYlvfT-Nqhw"
   },
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] Borucki, W. J., Koch, D. G., Basri, G., Batalha, N., Boss, A., Brown, T. M., ... & Dunham, E. W. (2011). *Characteristics of Kepler planetary candidates based on the first data set*. The Astrophysical Journal, 728(2), 117. also in: https://exoplanetarchive.ipac.caltech.edu/index.html  \n",
    "[2] Bugueno, M., Mena, F., & Araya, M. *Refining Exoplanet Detection Using Supervised Learning and Feature Engineering*.  \n",
    "[3] Sutskever, I., Martens, J., Dahl, G. E., & Hinton, G. E. (2013). *On the importance of initialization and momentum in deep learning*. ICML (3), 28(1139-1147), 5.  \n",
    "[4] Lin, T. Y., Goyal, P., Girshick, R., He, K., & Dollár, P. (2017). *Focal loss for dense object detection*. In Proceedings of the IEEE international conference on computer vision (pp. 2980-2988).  \n",
    "[5] Chen, P., Chen, Y., & Rao, M. (2008). *Metrics defined by Bregman divergences: Part 2*. Communications in Mathematical Sciences, 6(4), 927-948.  \n",
    "[6] Glorot, X., & Bengio, Y. (2010, March). *Understanding the difficulty of training deep feedforward neural networks*. In Proceedings of the thirteenth international conference on artificial intelligence and statistics (pp. 249-256).   \n",
    "[7] He, K., Zhang, X., Ren, S., & Sun, J. (2015). *Delving deep into rectifiers: Surpassing human-level performance on imagenet classification*. In Proceedings of the IEEE international conference on computer vision (pp. 1026-1034).    \n",
    "[8] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). *Dropout: a simple way to prevent neural networks from overfitting*. The Journal of Machine Learning Research, 15(1), 1929-1958.  \n",
    "[9] Ioffe, S., & Szegedy, C. (2015). Batch normalization: *Accelerating deep network training by reducing internal covariate shift*. arXiv preprint arXiv:1502.03167.  \n",
    "[10] Krizhevsky, A., Nair, V., & Hinton, G. (2014). *The CIFAR-10 dataset*. online: http://www.cs.toronto.edu/kriz/cifar.html , 4.  \n",
    "[11] Bengio, Y. (2012, June). *Deep learning of representations for unsupervised and transfer learning*. In Proceedings of ICML Workshop on Unsupervised and Transfer Learning (pp. 17-36).  \n",
    "[12] Simonyan, K., & Zisserman, A. (2014). *Very deep convolutional networks for large-scale image recognition*. arXiv preprint arXiv:1409.1556.  \n",
    "[13] Ruder, S. (2017). *An overview of multi-task learning in deep neural networks*. arXiv preprint arXiv:1706.05098.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propuesta\n",
    "---\n",
    "1. **Experimentar con parámetros básicos de una red feed forward**\n",
    "2. **Entrenar eficazmente una red profunda**  \n",
    "3. **Ingenerizar una red para resolver un problema real**\n",
    "    * Dominar lenguaje básico de redes conv (strides, número de filtros, tamaño de kernel)\n",
    "4. **predecir el ozono de mañana**\n",
    "    * Ellos deben construir la serie de tiempo (time step y features)\n",
    "    * Variar lag, es mejor en timestep o features?\n",
    "    * Predecir el siguiente valor de una serie de tiempo: Ozono\n",
    "    * Primera parte solo con ozono, después agregar nuevos predictores\n",
    "    * time folding experiment"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Enunciado.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
