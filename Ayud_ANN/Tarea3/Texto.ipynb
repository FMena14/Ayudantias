{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interesante**: traduccion http://www.mn.uio.no/ifi/english/research/groups/ltg/news/new-corpus-release%3A-opensubtitles-2016.html\n",
    "\n",
    "* 1 redes recurrentes en series de tiempo  \n",
    "\n",
    "* 2 Redes recurrentes sobre texto  \n",
    "    * quora (2 sentences) https://medium.com/mlreview/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07  \n",
    "    * clasificacion de texto con CNN - https://www.kaggle.com/eliotbarr/text-mining-with-sklearn-keras-mlp-lstm-cnn  con ese mismo dataset autocompletar (puede generar despues) https://chunml.github.io/ChunML.github.io/project/Creating-Text-Generator-Using-Recurrent-Neural-Network/\n",
    "https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "    * Annotation text https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus/data\n",
    "\n",
    "* 3 Autoencoder  \n",
    "* 4 regulerazacion en CNN -meter batch normalization con transferlearning\n",
    "\n",
    "Para cambiar batch size de red: https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 281837: expected 25 fields, saw 34\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>...</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>...</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>...</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>...</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "0           0  thousand         of        demonstr           NNS   \n",
       "1           1        of   demonstr            have           VBP   \n",
       "2           2  demonstr       have           march           VBN   \n",
       "3           3      have      march         through            IN   \n",
       "4           4     march    through          london           NNP   \n",
       "\n",
       "  next-next-shape next-next-word next-pos next-shape      next-word ...  \\\n",
       "0       lowercase  demonstrators       IN  lowercase             of ...   \n",
       "1       lowercase           have      NNS  lowercase  demonstrators ...   \n",
       "2       lowercase        marched      VBP  lowercase           have ...   \n",
       "3       lowercase        through      VBN  lowercase        marched ...   \n",
       "4     capitalized         London       IN  lowercase        through ...   \n",
       "\n",
       "  prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word   prev-shape  \\\n",
       "0      __start2__    __START2__        wildcard     __START2__     wildcard   \n",
       "1      __start1__    __START1__        wildcard     __START1__  capitalized   \n",
       "2        thousand           NNS     capitalized      Thousands    lowercase   \n",
       "3              of            IN       lowercase             of    lowercase   \n",
       "4        demonstr           NNS       lowercase  demonstrators    lowercase   \n",
       "\n",
       "       prev-word sentence_idx        shape           word tag  \n",
       "0     __START1__          1.0  capitalized      Thousands   O  \n",
       "1      Thousands          1.0    lowercase             of   O  \n",
       "2             of          1.0    lowercase  demonstrators   O  \n",
       "3  demonstrators          1.0    lowercase           have   O  \n",
       "4           have          1.0    lowercase        marched   O  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "folder = './entity-annotated-corpus'\n",
    "\n",
    "df_ner = pd.read_csv(folder+\"/ner.csv\", error_bad_lines=False)\n",
    "df_ner.dropna(inplace=True)\n",
    "#df_ner.drop(['Unnamed: 0', 'sentence_idx', 'tag'], axis=1,inplace=True)\n",
    "df_ner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050794, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'lemma', u'next-lemma', u'next-next-lemma', u'next-next-pos',\n",
       "       u'next-next-shape', u'next-next-word', u'next-pos', u'next-shape',\n",
       "       u'next-word', u'pos', u'prev-iob', u'prev-lemma', u'prev-pos',\n",
       "       u'prev-prev-iob', u'prev-prev-lemma', u'prev-prev-pos',\n",
       "       u'prev-prev-shape', u'prev-prev-word', u'prev-shape', u'prev-word',\n",
       "       u'shape', u'word'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>prev-iob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>__START1__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lemma  pos tag    prev-iob\n",
       "0  thousand  NNS   O  __START1__\n",
       "1        of   IN   O           O\n",
       "2  demonstr  NNS   O           O\n",
       "3      have  VBP   O           O\n",
       "4     march  VBN   O           O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_ner.loc[:,[\"lemma\",\"pos\",\"tag\",\"prev-iob\"]]#porque lemma y no word?\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = []\n",
    "label_sentence = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47959 sentencias etiquetadas con tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48082\n"
     ]
    }
   ],
   "source": [
    "#load data into shape \n",
    "dataX,dataY = [],[]\n",
    "datos = 0\n",
    "#uniques\n",
    "lemmas = []\n",
    "labels = []\n",
    "for fila in dataset.values:\n",
    "    if fila[-1]==\"__START1__\": \n",
    "        dataX.append(np.asarray(sentence))\n",
    "        dataY.append(np.asarray(label_sentence))\n",
    "        sentence= []\n",
    "        label_sentence = []\n",
    "        datos+=1\n",
    "    lemmas.append(fila[0])\n",
    "    labels.append(fila[1])\n",
    "    sentence.append(fila[0])#add lemma\n",
    "    label_sentence.append(fila[1]) #POS o TAG\n",
    "lemmas = list(set(lemmas)) \n",
    "labels = list(set(labels))\n",
    "#data to \n",
    "dataX = np.asarray(dataX[1:])\n",
    "dataY = np.asarray(dataY[1:])\n",
    "    \n",
    "print(datos)  \n",
    "\n",
    "#array = [ejemplos,timestepts=largo,wordembeding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['thousand', 'of', 'demonstr', 'have', 'march', 'through', 'london',\n",
       "       'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand',\n",
       "       'the', 'withdraw', 'of', 'british', 'troop', 'from', 'that',\n",
       "       'countri', '.'], dtype='|S8'),\n",
       "       array(['famili', 'of', 'soldier', 'kill', 'in', 'the', 'conflict', 'join',\n",
       "       'the', 'protest', 'who', 'carri', 'banner', 'with', 'such',\n",
       "       'slogan', 'as', '\"', 'bush', 'number', 'one', 'terrorist', '\"',\n",
       "       'and', '\"', 'stop', 'the', 'bomb', '.', '\"'], dtype='|S9'),\n",
       "       array(['they', 'march', 'from', 'the', 'hous', 'of', 'parliament', 'to',\n",
       "       'a', 'ralli', 'in', 'hyde', 'park', '.'], dtype='|S10'),\n",
       "       ...,\n",
       "       array(['indian', 'offici', 'said', 'no', 'one', 'was', 'injur', 'in',\n",
       "       'saturday', \"'s\", 'incid', 'but', 'that', 'two', 'of', 'the',\n",
       "       'rocket', 'land', 'near', 'a', 'border', 'secur', 'outpost', '.'],\n",
       "      dtype='|S8'),\n",
       "       array(['two', 'more', 'land', 'in', 'field', 'belong', 'to', 'a',\n",
       "       'nearbi', 'villag', '.'], dtype='|S6'),\n",
       "       array(['they', 'say', 'not', 'all', 'of', 'the', 'rocket', 'explod',\n",
       "       'upon', 'impact', '.'], dtype='|S6')], dtype=object)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20246\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "#cantidad de lemas y cantidad de etiquetas\n",
    "print(len(lemmas))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf3d139e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = map(len, dataX)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.boxplot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting words to numbers\n",
    "lemmas = [\"ENDPAD\"]+lemmas\n",
    "labels = [\"END\"]+labels #agregar caracter espacial para fin de texto\n",
    "lemma2idx = {w: i for i, w in enumerate(lemmas)}\n",
    "lab2idx = {t: i for i, t in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-768e6df56ccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_input_lenght\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_lemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_input_lenght\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "max_input_lenght = max(result)\n",
    "n_lemmas = len(lemmas)\n",
    "n_labels = len(labels)\n",
    "max_input_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-94ef68370bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'n_labels' is not defined"
     ]
    }
   ],
   "source": [
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3042"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "lemma2idx['obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[22,\n",
       "  34,\n",
       "  22,\n",
       "  6,\n",
       "  31,\n",
       "  34,\n",
       "  23,\n",
       "  17,\n",
       "  24,\n",
       "  11,\n",
       "  14,\n",
       "  34,\n",
       "  23,\n",
       "  27,\n",
       "  24,\n",
       "  11,\n",
       "  14,\n",
       "  34,\n",
       "  8,\n",
       "  22,\n",
       "  34,\n",
       "  11,\n",
       "  14,\n",
       "  16],\n",
       " [22,\n",
       "  34,\n",
       "  22,\n",
       "  31,\n",
       "  34,\n",
       "  11,\n",
       "  14,\n",
       "  3,\n",
       "  11,\n",
       "  22,\n",
       "  9,\n",
       "  3,\n",
       "  22,\n",
       "  34,\n",
       "  8,\n",
       "  22,\n",
       "  34,\n",
       "  4,\n",
       "  23,\n",
       "  14,\n",
       "  36,\n",
       "  14,\n",
       "  4,\n",
       "  27,\n",
       "  4,\n",
       "  24,\n",
       "  11,\n",
       "  22,\n",
       "  16,\n",
       "  4],\n",
       " [18, 3, 34, 11, 22, 34, 14, 17, 11, 14, 34, 23, 23, 16],\n",
       " [22, 3, 11, 14, 34, 22, 34, 36, 34, 22, 3, 18, 3, 36, 16],\n",
       " [11,\n",
       "  14,\n",
       "  10,\n",
       "  34,\n",
       "  11,\n",
       "  14,\n",
       "  34,\n",
       "  11,\n",
       "  8,\n",
       "  14,\n",
       "  34,\n",
       "  23,\n",
       "  15,\n",
       "  2,\n",
       "  23,\n",
       "  23,\n",
       "  34,\n",
       "  11,\n",
       "  8,\n",
       "  8,\n",
       "  14,\n",
       "  14,\n",
       "  34,\n",
       "  23,\n",
       "  16]]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX = [[lemma2idx[lemma] for lemma in sentence ] for sentence in dataX]\n",
    "dataY = [[lab2idx[pos] for pos in pos_tags ] for pos_tags in dataY]\n",
    "\n",
    "dataY[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2075, 17581,  5343, ...,     0,     0,     0],\n",
       "       [ 7753, 17581,  7728, ...,     0,     0,     0],\n",
       "       [ 5427,  8570, 19165, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 3866, 12086, 10840, ...,     0,     0,     0],\n",
       "       [12861,  2708,  3730, ...,     0,     0,     0],\n",
       "       [ 5427,  1824,  6696, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "X = sequence.pad_sequences(dataX, maxlen=max_input_lenght,padding='post',value=lemma2idx[\"ENDPAD\"]) #o pre\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22, 34, 22, ...,  0,  0,  0],\n",
       "       [22, 34, 22, ...,  0,  0,  0],\n",
       "       [18,  3, 34, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 8, 22,  3, ...,  0,  0,  0],\n",
       "       [36, 40,  3, ...,  0,  0,  0],\n",
       "       [18,  6, 19, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sequence.pad_sequences(dataY, maxlen=max_input_lenght,padding='post',value=lab2idx[\"END\"])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arreglo tridimensional para etiquetas [ejemplos,palabras,tag en one hot]\n",
    "from keras.utils import to_categorical\n",
    "y = np.asarray([to_categorical(i, num_classes=n_labels) for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dimensiones X', (33656, 81))\n",
      "('Dimensiones X', (14425, 81))\n",
      "('Dimensiones y: ', (14425, 81, 42))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=22)\n",
    "print(\"Dimensiones X\",X_train.shape)\n",
    "print(\"Dimensiones X\",X_test.shape)\n",
    "print(\"Dimensiones y: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 15, 10)            100       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 15, 100)           44400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15, 20)            2020      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15, 20)            420       \n",
      "=================================================================\n",
      "Total params: 46,940\n",
      "Trainable params: 46,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f2ca9ad6ee38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#many to many net\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "\n",
    "embedding_vector = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))\n",
    "model.add(LSTM(units=100,return_sequences=True))\n",
    "model.add(Dense(n_labels, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.953644436480061)\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy:\",scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 81, 32)            647808    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 81, 200)           106400    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 81, 42)            8442      \n",
      "=================================================================\n",
      "Total params: 762,650\n",
      "Trainable params: 762,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 117s 3ms/step - loss: 0.9675 - acc: 0.7594 - val_loss: 0.7063 - val_acc: 0.8039\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 117s 3ms/step - loss: 0.4850 - acc: 0.8707 - val_loss: 0.2533 - val_acc: 0.9348\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 117s 3ms/step - loss: 0.1627 - acc: 0.9576 - val_loss: 0.1171 - val_acc: 0.9674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf1d353c10>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))\n",
    "#dropout?\n",
    "layer_lstm = LSTM(units=100,return_sequences=True)\n",
    "#LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)\n",
    "model.add(Bidirectional(layer_lstm))\n",
    "model.add(Dense(n_labels, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.9673671811168281)\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy:\",scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma          : Pred\n",
      "amnesti        : NNP\n",
      "also           : RB\n",
      "accus          : VBD\n",
      "eritrean       : JJ\n",
      "prison         : NNS\n",
      "offici         : NNS\n",
      "of             : IN\n",
      "open           : VBG\n",
      "fire           : NN\n",
      "on             : IN\n",
      "detaine        : NNS\n",
      "at             : IN\n",
      "the            : DT\n",
      "adi            : NNP\n",
      "abeto          : NNP\n",
      "prison         : NN\n",
      "dure           : IN\n",
      "an             : DT\n",
      "appar          : JJ\n",
      "escap          : VBD\n",
      "attempt        : NN\n",
      "follow         : VBG\n",
      "the            : DT\n",
      "arrest         : NN\n",
      ".              : .\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n",
      "ENDPAD         : END\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "p = model.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(\"{:15}: {}\".format(\"Lemma\", \"Pred\"))\n",
    "for w,pred in zip(X_test[i],p[0]):\n",
    "    print(\"{:15}: {}\".format(lemmas[w],labels[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOCOMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>prev-iob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>__START1__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word     lemma next-lemma    prev-iob\n",
       "0      Thousands  thousand         of  __START1__\n",
       "1             of        of   demonstr           O\n",
       "2  demonstrators  demonstr       have           O\n",
       "3           have      have      march           O\n",
       "4        marched     march    through           O"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_ner.loc[:,[\"word\",\"lemma\",\"next-lemma\",\"prev-iob\"]]#porque lemma y no word?\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6067512\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(dataset[\"word\"]).lower() #corpus\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'char_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c7edb9a06647>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"$\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'char_indices' is not defined"
     ]
    }
   ],
   "source": [
    "char_indices[\"$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total chars:', 72)\n",
      "('nb sequences:', 242693)\n"
     ]
    }
   ],
   "source": [
    "null_character = \"*\"\n",
    "chars = [null_character]+sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 5 \n",
    "sentences = []\n",
    "next_chars = []\n",
    "size = int(len(text)*0.2) #solo un 20% del corpus\n",
    "for i in range(0, size - maxlen, step):\n",
    "    sentences.append(null_character+text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*thousands of demonstrators have marched ',\n",
       " '*ands of demonstrators have marched throu',\n",
       " '*of demonstrators have marched through lo',\n",
       " '*monstrators have marched through london ',\n",
       " '*rators have marched through london to pr']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52, 39, 46, 52, 47]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX = [[char_indices[char] for char in sentence ] for sentence in sentences]\n",
    "dataY = [char_indices[char] for char in next_chars]\n",
    "\n",
    "dataY[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242693, 41)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "X = sequence.pad_sequences(dataX, maxlen=maxlen+1,padding='pre',value=char_indices[null_character]) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242693, 72)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arreglo tridimensional para etiquetas [ejemplos,palabras,tag en one hot]\n",
    "from keras.utils import to_categorical\n",
    "y = np.asarray([to_categorical(i, num_classes=len(chars)) for i in dataY])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, 41, 16)            1152      \n",
      "_________________________________________________________________\n",
      "cu_dnngru_27 (CuDNNGRU)      (None, 512)               814080    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 72)                36936     \n",
      "=================================================================\n",
      "Total params: 852,168\n",
      "Trainable params: 852,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, Dropout,CuDNNGRU\n",
    "\n",
    "embedding_vector = 16\n",
    "model = Sequential()\n",
    "#model.add(Input(batch_shape=(256,maxlen+1)))\n",
    "model.add(Embedding(input_dim=len(chars), output_dim=embedding_vector, input_length=maxlen+1))#\n",
    "#model.add(CuDNNGRU(units=32,return_sequences=True)) \n",
    "model.add(CuDNNGRU(units=512,return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "242693/242693 [==============================] - 33s 134us/step - loss: 2.4705 - acc: 0.2862\n",
      "()\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"h little or no documentation during 2003\"\n",
      "h little or no documentation during 2003 aps angean . the poremith lithlung ja ter of collien palotians fors ala and sotie clunawiot cullo lead ins siburs ind pareistroes . prition cof suntschd ta dimre as insean atedte 36-iscof tish frbizictar as cuna's . ang aes , s5yg reyed to real wass a perestaitidg cneplofr . in suront hist moth etsicial stitions erenn silunit of tourevar hent ir mimany . mationicis joncomt of caterinel e res alelEpoch 2/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 1.9253 - acc: 0.4317\n",
      "()\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"not want to give the opposition an excus\"\n",
      "not want to give the opposition an excusian gasing a coseing to khind all searling fre the gusting nuply scallunt fil themere ank grjargument insiliming te point the plastenng has . there dman cate-stat of for gorp rehate offshurf isfan in treo ouf fired yun recust buchity the state and stotimitast raturt of his tocpest alsiprenterer m. hus burithrated nop insolliansaun fraceac a soith serfile sonziters spootest alia con ince a gaph a pEpoch 3/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 1.6661 - acc: 0.5103\n",
      "()\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"ese state media say at least 11 miners a\"\n",
      "ese state media say at least 11 miners aed in ausaft about ) it sald a bound . prant . the work 's commintle new to resudes there and kereuphonech to mougtade by medaicate agbict to cunt for the rechine agcused ta hindse begused 17 killed for western postladoni for junien tereghaniby algodaliz the cotuvity in the brast recelnance says crusher a foller in 1904 , and wounded 's atophate changer jonder suonteral iar beave fild that to moreEpoch 4/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 1.5062 - acc: 0.5557\n",
      "()\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"ps for the next six months to provide te\"\n",
      "ps for the next six months to provide tedmara is claminguration incedeation forces . brefors . said the growating . a hasharra ig ina uffict bus trud of the secrets agtinitation about renelous conldysdon1d what to group af last contedbateres . dis . met saturday , which polese and rosain 's decision to reich treat cresidiation assaigeving of wost seotemaning of romin furmond to dayest the condiction province last wonking , whechee termoEpoch 5/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 1.3956 - acc: 0.5861\n",
      "()\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \" to be \" unacceptable . \" that remark is\"\n",
      " to be \" unacceptable . \" that remark is anousce to gre takors in the mahinoth sudar manters un officials say the last mantle . keenes agency said tuakus , bouring and out friday , mose volal , pakistani lowar to gaxe television fert is an julla and contoration . a trifical domnss of the binding a takila delien spowesman fass farists chingence was killed a prepact , wjich that housejy and trusen release of ntithen witnesses colliescous Epoch 6/25\n",
      "242693/242693 [==============================] - 30s 123us/step - loss: 1.3104 - acc: 0.6086\n",
      "()\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"ptian authorities say a construction com\"\n",
      "ptian authorities say a construction compai deal haute of and earmints in the chizure , israeli atman . me nestecura 'r 's accidents hasten a boy-bly ruct to the provicces in leading other international official asses were killed in a stide that but meening six prace . passew . the fifrting formelly kee into dead and cation . that officials war in the hel0 should was al-oas and incausers to renear . eaklisting thoops of former peace proEpoch 7/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 1.2368 - acc: 0.6285\n",
      "()\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"eace talks with eta if it renounces viol\"\n",
      "eace talks with eta if it renounces violence in scanth-to vilitary syat his fassshipf 's he in the northern idvestments in south asis it will be cricas . foreign ungor a qoois- country along its new later gaizal and officials are centlating afghan strikes dead from but 800 diotctol ann sascroush . cansipalt killed at least 450 promolan government in 2009 . whith has year pushed to find the north aside fire that plan to russian 'sar ocyoEpoch 8/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 1.1709 - acc: 0.6459\n",
      "()\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"me minister questions for more than an h\"\n",
      "me minister questions for more than an hoditian-lures counted to the allorities since the u.s. potently before he ex calling for the nive said over 10 years of his abeas . an omporition forces say the taleben for with a nuclear rearty . the country 's president deads and economic refuted at afghanistan in group goor pressured to gossing a beijut the one thoos olless from toly himherw killia caring ikas and services . the jebussal companEpoch 9/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 1.1111 - acc: 0.6624\n",
      "()\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \" barrels . opec 's 11 members supply nea\"\n",
      " barrels . opec 's 11 members supply near the allical is brucking bayharre says at least 19 people and 30 deaths and nual a news aganch atreet miner last aptraliate officials say the twa mrass .hbal fludst at an intemparing basin sunca privonman for sector and mr. turga president barroushar pouldy of two parts say grefter frueg the was-linied . saftal west knngjent and more than two maintains agency . some urgen 's capital , sowe detenmEpoch 10/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 1.0588 - acc: 0.6767\n",
      "()\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \" ocean researchers . the largest of sea \"\n",
      " ocean researchers . the largest of sea on january 1 96 dillion togun into suicide bomb in byinon's wat that the has the wromp . entingent water killed u. . on sated a trood could kasembul detail to releas used a now by taykere along it ho office is the palestinian police american jow punhed in fren who warsee fral majority says at dildrein geres attacken and had industratisnantise the gionts for the allormed after venezuelan president Epoch 11/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 1.0133 - acc: 0.6897\n",
      "()\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \"poor . only 35 percent said they approve\"\n",
      "poor . only 35 percent said they approvers angest of wish what has been wollled good final program . the press and loins acter comments for harreing changes . dusing world has been to build a zung exparises in new derghons of bolboronis said an ergep of government from the large- and officials say prading is south afraccian activists wallound maze along high chinese russian news agency is an indoceming a police china as a stronghed has Epoch 12/25\n",
      "242693/242693 [==============================] - 30s 124us/step - loss: 0.9708 - acc: 0.7013\n",
      "()\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \"dia standards and not limit free speech \"\n",
      "dia standards and not limit free speech suburd raheanced the bunls scheduled to coldiearon hos it centrol american since 2033 - two mar prover in the end of the unete term in northeestern arrests say sandan from nailam wesher of india and still not ended inle were beantrich and sunci meolong of the rejucting fel ball colls massai space shippents to the abazoma law the afghan weten is candidate for hurricane ked rividing president 's heaEpoch 13/25\n",
      "242693/242693 [==============================] - 30s 125us/step - loss: 0.9394 - acc: 0.7094\n",
      "()\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \"ian military helicopters are ferrying ou\"\n",
      "ian military helicopters are ferrying outside the vounding reparts bote foredanian notileted likely , which was sinde in the convated by u.s. to crack of the o6250 claim that china and of the palestinian court ressines . juszels and government vein auding and the also as a former nations leaders from the resignation for economic , fires showed from the international situation . granshing allegationing the pla mericuntly were killed and Epoch 14/25\n",
      "242693/242693 [==============================] - 30s 123us/step - loss: 0.9101 - acc: 0.7187\n",
      "()\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \" be indicted . they are accused of viole\"\n",
      " be indicted . they are accused of violence insistant man outbbean senvine as issee such cevention of death of election . mr. bughd last served to be investigated for man has new detention . he also discussed sepreary says out of the constitution will be released the president has strained the government , considers . hurricane says his possibility , recovering in the betaine , has officed hater and offenese rafely and imention , captasEpoch 15/25\n",
      "242693/242693 [==============================] - 30s 123us/step - loss: 0.8887 - acc: 0.7241\n",
      "()\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"ot much past midfield . their best chanc\"\n",
      "ot much past midfield . their best chance and have repeared monday since itany of thousands of heavers . in the european union , under . a jas bether west bank , capital , khathin show has blen talker of find toly taxk accused the united states has left the winne police . many cussions farrught notion . afghan profocal cordennis , israel discuss estimated polace . group gas monday was stated stold controlled by hary a thirds on dildidenEpoch 16/25\n",
      "242693/242693 [==============================] - 30s 123us/step - loss: 0.8755 - acc: 0.7271\n",
      "()\n",
      "----- Generating text after Epoch: 15\n",
      "----- Generating with seed: \"enrichment activities , staving off a u.\"\n",
      "enrichment activities , staving off a u.s. and others have been supplyed early termorist claim sist essisant suspected has deans the presidential presidential espeksion , and one of all says it has proved states on board and estimates the two countries who her  antiors of dumank , where he in oberatices a roudd , the sunni mes , who 's aroudd 20 2 percenting that is commented in the head of civilians were killed in masy more than 21 othEpoch 17/25\n",
      "242693/242693 [==============================] - 30s 122us/step - loss: 0.8670 - acc: 0.7300\n",
      "()\n",
      "----- Generating text after Epoch: 16\n",
      "----- Generating with seed: \"rman chancellor angela merkel threatened\"\n",
      "rman chancellor angela merkel threatened to generation wednesday , all abturl assevend protests say they hopeled the rest deminsted remotian ( $6130 dassing the political crisis . saming a fled the world 's report released friday not over ane relatives one of the reporters were krypent for the israeli prime minister vussil and arm sass the relefs to return to wis grawted the revelues of two offension , and pakestanned some fow sunni menEpoch 18/25\n",
      "242693/242693 [==============================] - 30s 123us/step - loss: 0.8622 - acc: 0.7297\n",
      "()\n",
      "----- Generating text after Epoch: 17\n",
      "----- Generating with seed: \"ith it . since then , there have been no\"\n",
      "ith it . since then , there have been no plated marchan epolonament are killing of the ele tiossing the palestinian authority groups elections and designation of all attacks against congress that were located to stop when a gunan plame is to ablust about anian percent and was trace ending . but the commissee haw record assist thursday by a diffecen police . a somilation of weapons on thousands of delay by the country 's planies , day thEpoch 19/25\n",
      "242693/242693 [==============================] - 30s 123us/step - loss: 0.8524 - acc: 0.7335\n",
      "()\n",
      "----- Generating text after Epoch: 18\n",
      "----- Generating with seed: \"itants were killed in the clashes , alon\"\n",
      "itants were killed in the clashes , along with 20 people war announced . ons to the mei ani commoskif war . somalia . the united states and otten tilet chance of a gis-2--19- diem , ali gavirian militants were barded posts and foreign aids . by the acris . the charren deading sliday ray of the sextely and the men are attedpting terrorists have been killed in the teat hupand 's president and stalist , which reputed and ifforente he says Epoch 20/25\n",
      "242693/242693 [==============================] - 30s 122us/step - loss: 0.8519 - acc: 0.7326\n",
      "()\n",
      "----- Generating text after Epoch: 19\n",
      "----- Generating with seed: \"eer khan confessed last year to illegall\"\n",
      "eer khan confessed last year to illegally entersions of fatilition that is consements . the president violance . arrives in new debhit of the capital . the are in the country 's suslim . consume that is not terrorism and number 9 , marning the u.s. after two pullicationational metoricion in jean . thr ustem , 301 authorities sionces to tee ants of vatur , where , ay a swiol in the oreninations . fire about the two weeks ago the attacks Epoch 21/25\n",
      "242693/242693 [==============================] - 30s 122us/step - loss: 0.8432 - acc: 0.7343\n",
      "()\n",
      "----- Generating text after Epoch: 20\n",
      "----- Generating with seed: \"he plant 's opening has frequently been \"\n",
      "he plant 's opening has frequently been in hig the chancel before the vice prosecutoor . the yuran published three decommer president and the public toat peace pallial israeli mannof service survessessed . people in washanaring iran , says he is mr. aha make and about 14 's relataers . the uking state . south africa and police say at least 32 million people are in part of americans , which sasseir demonstrations and 30 people were killeEpoch 22/25\n",
      "242693/242693 [==============================] - 30s 122us/step - loss: 0.8415 - acc: 0.7351\n",
      "()\n",
      "----- Generating text after Epoch: 21\n",
      "----- Generating with seed: \"of toluca when it went down late friday \"\n",
      "of toluca when it went down late friday on the reporters under him until in a nex itporing . more than 800 people led 's contion for aroun police at mr. nafi masha has deficattac . turkey has killed a sascord democrats qune as a statement wings of the report as part of a cormunion in the killing with they a leng to to unsurg of of bexint to the talks on a rrigofe of current reports declined for a nual election . voco called for foreign Epoch 23/25\n",
      "242693/242693 [==============================] - 29s 121us/step - loss: 0.8399 - acc: 0.7343\n",
      "()\n",
      "----- Generating text after Epoch: 22\n",
      "----- Generating with seed: \" appearance friday , a day after being e\"\n",
      " appearance friday , a day after being explosion down an insecembiab . the official election . response military offersed for several years agun yid expard in december for peeside and mown-eler and killes in discussed at \" . in police . this year , faim to have denied a car not between the washington had 1935 metts , cancien the new government says the official sand the same ifal hele continuing . y ond in the rebels have the ple guiresEpoch 24/25\n",
      "242693/242693 [==============================] - 30s 122us/step - loss: 0.8504 - acc: 0.7317\n",
      "()\n",
      "----- Generating text after Epoch: 23\n",
      "----- Generating with seed: \"on government installations . baluch tri\"\n",
      "on government installations . baluch trial demonstry of the capital , who ofisu guth in the strice of lash not of western urit of bulamodia and its meeting bomby on monday . eher is almed tilest pokition facility at guva frow his asanated the elections assected brokeverto has elected in helb prisof . ne ond monday , considered in early expects of international assistant nocalito sundin bermen miditary has subcled in ginonm . nothing estEpoch 25/25\n",
      "242693/242693 [==============================] - 30s 122us/step - loss: 0.8506 - acc: 0.7313\n",
      "()\n",
      "----- Generating text after Epoch: 24\n",
      "----- Generating with seed: \"ocrat barack obama released statements f\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocrat barack obama released statements for an al-qaida province services head of the siden minister says the delg eastern europe and a ship by consul- . the assassination to baged their warmage until hel constitution and second ligg the move , western makarha chaines a permanent south karmed sutsestian more gand has deneesed was month alolia has cleared not to the virus . masar acinities year attack in southern mil-or president diructio"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efd65055e50>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\"\"\"\n",
    "\n",
    "def predict_next_char(model, sentence, diversity=1.0):\n",
    "    \"\"\"Predict the next character from the current one\"\"\"    \n",
    "    x_pred = [char_indices[null_character]]+[char_indices[char] for char in sentence]\n",
    "    x_pred = sequence.pad_sequences([x_pred], maxlen=maxlen+1,padding='pre',value=char_indices[null_character])\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    #next_index = sample(preds, diversity)\n",
    "    #next_index = np.argmax(preds)\n",
    "    next_index = np.random.choice(len(chars), p=preds)\n",
    "    return indices_char[next_index]\n",
    "\n",
    "import random,sys\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    #for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "     #   print('----- diversity:', diversity)\n",
    "\n",
    "    #generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    #generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(sentence)\n",
    "\n",
    "    for i in range(400):\n",
    "        next_char = predict_next_char(model, sentence)\n",
    "        sentence = sentence[1:] + next_char #for next character\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "from keras.callbacks import LambdaCallback\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(X, y,batch_size=256,epochs=25, callbacks=[print_callback])\n",
    "\n",
    "#N = 256*700\n",
    "#for i in range(25):\n",
    "#    model.fit(X[:N], y[:N], epochs=1, batch_size=256, verbose=1, shuffle=False,callbacks=[print_callback])\n",
    "#    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-898aedd92df4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"text_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como es por caracter.. puede recibir cualquier palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"text_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "def predict_next_char(model, sentence, diversity=1.0):\n",
    "    \"\"\"Predict the next character from the current one\"\"\"    \n",
    "    x_pred = [char_indices[null_character]]+[char_indices[char] for char in sentence]\n",
    "    x_pred = sequence.pad_sequences([x_pred], maxlen=maxlen+1,padding='pre',value=char_indices[null_character])\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    #next_index = np.random.choice(len(chars), p=preds)\n",
    "    next_index = np.argmax(preds)\n",
    "    return indices_char[next_index]\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"my name is \"\n",
      "my name is "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'char_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-09052926fc4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_next_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_char\u001b[0m \u001b[0;31m#for next character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6e883f285eaa>\u001b[0m in \u001b[0;36mpredict_next_char\u001b[0;34m(model, sentence, diversity)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_next_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Predict the next character from the current one\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnull_character\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnull_character\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'char_indices' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = \"my name is \"#\"as a mirror, that the deep heavens may !\" #rellenar con un simbolo de \"null\" #\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "sys.stdout.write(sentence)\n",
    "for i in range(400):\n",
    "    next_char = predict_next_char(model, sentence)\n",
    "    sentence = sentence[1:] + next_char #for next character\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "sentence = \"this is a test \"\n",
    "\n",
    "x_pred = [char_indices[end_character]]+[char_indices[char] for char in sentence ]\n",
    "x_pred = sequence.pad_sequences([x_pred], maxlen=maxlen+1,padding='pre',value=char_indices[end_character])\n",
    "preds = model.predict(x_pred, verbose=0)[0]\n",
    "\n",
    "print(np.argmax(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
