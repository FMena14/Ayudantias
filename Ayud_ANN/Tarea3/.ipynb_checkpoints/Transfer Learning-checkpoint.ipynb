{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panshop/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 119s 1us/step\n",
      "169017344/169001437 [==============================] - 119s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_LABELS_LIST = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyboard\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e00d85610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i = 15\n",
    "print(CIFAR100_LABELS_LIST[y_train[i][0]])\n",
    "plt.imshow(x_train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=100)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_71 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 100)               102500    \n",
      "=================================================================\n",
      "Total params: 4,363,396\n",
      "Trainable params: 4,363,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Conv2D,MaxPooling2D\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:],activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 3.8680 - acc: 0.1157 - val_loss: 3.3943 - val_acc: 0.1993\n",
      "Epoch 2/12\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 3.1017 - acc: 0.2508 - val_loss: 2.8558 - val_acc: 0.3069\n",
      "Epoch 3/12\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 2.6545 - acc: 0.3354 - val_loss: 2.5178 - val_acc: 0.3670\n",
      "Epoch 4/12\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 2.3180 - acc: 0.4059 - val_loss: 2.3428 - val_acc: 0.3977\n",
      "Epoch 5/12\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 2.0338 - acc: 0.4671 - val_loss: 2.2577 - val_acc: 0.4240\n",
      "Epoch 6/12\n",
      "50000/50000 [==============================] - 75s 2ms/step - loss: 1.7725 - acc: 0.5245 - val_loss: 2.2118 - val_acc: 0.4358\n",
      "Epoch 7/12\n",
      "50000/50000 [==============================] - 84s 2ms/step - loss: 1.5309 - acc: 0.5839 - val_loss: 2.2705 - val_acc: 0.4464\n",
      "Epoch 8/12\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.2935 - acc: 0.6379 - val_loss: 2.2928 - val_acc: 0.4491\n",
      "Epoch 9/12\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 1.0961 - acc: 0.6875 - val_loss: 2.3855 - val_acc: 0.4504\n",
      "Epoch 10/12\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.9278 - acc: 0.7286 - val_loss: 2.4876 - val_acc: 0.4436\n",
      "Epoch 11/12\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 0.8020 - acc: 0.7631 - val_loss: 2.6876 - val_acc: 0.4556\n",
      "Epoch 12/12\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.7146 - acc: 0.7878 - val_loss: 2.6689 - val_acc: 0.4512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d8ffabd10>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, nb_epoch=12, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 4.6036 - acc: 0.0112 - val_loss: 4.6067 - val_acc: 0.0100\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 4.6080 - acc: 0.0091 - val_loss: 4.6064 - val_acc: 0.0100\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 4.6080 - acc: 0.0092 - val_loss: 4.6060 - val_acc: 0.0100\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 4.6079 - acc: 0.0090 - val_loss: 4.6060 - val_acc: 0.0100\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 4.6077 - acc: 0.0094 - val_loss: 4.6064 - val_acc: 0.0100\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 4.6078 - acc: 0.0095 - val_loss: 4.6060 - val_acc: 0.0100\n",
      "Epoch 7/15\n",
      "13952/50000 [=======>......................] - ETA: 45s - loss: 4.6074 - acc: 0.0097"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-9bae5a7a9cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer_ = SGD(lr=0.1,momentum=0.9,decay=1e-6) #probar con lr =0.1 sino gg\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, nb_epoch=15, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 4.2933 - acc: 0.0501 - val_loss: 3.8551 - val_acc: 0.1128\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 3.7611 - acc: 0.1285 - val_loss: 3.4727 - val_acc: 0.1789\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.4237 - acc: 0.1857 - val_loss: 3.1681 - val_acc: 0.2415\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.1165 - acc: 0.2427 - val_loss: 2.9325 - val_acc: 0.2881\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 2.8586 - acc: 0.2926 - val_loss: 2.7199 - val_acc: 0.3261\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 2.6208 - acc: 0.3389 - val_loss: 2.5820 - val_acc: 0.3585\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 2.3987 - acc: 0.3840 - val_loss: 2.5011 - val_acc: 0.3728\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 2.2055 - acc: 0.4247 - val_loss: 2.4134 - val_acc: 0.3959\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 2.0072 - acc: 0.4685 - val_loss: 2.3684 - val_acc: 0.4067\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.8155 - acc: 0.5080 - val_loss: 2.3749 - val_acc: 0.4100\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.6316 - acc: 0.5514 - val_loss: 2.3586 - val_acc: 0.4159\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.4302 - acc: 0.5974 - val_loss: 2.4526 - val_acc: 0.4074\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.2698 - acc: 0.6345 - val_loss: 2.4603 - val_acc: 0.4221\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 1.1013 - acc: 0.6792 - val_loss: 2.5499 - val_acc: 0.4162\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.9540 - acc: 0.7173 - val_loss: 2.6340 - val_acc: 0.4068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d8a4ea390>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_ = SGD(lr=0.1,momentum=0.9,decay=1e-6) #probar con lr =0.1 sino gg\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, nb_epoch=15, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy:', 0.4068)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donde dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder pre training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "#modify for th dim ordering\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(16, 3, 3, activation='relu', border_mode='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), border_mode='same')(x)\n",
    "x = Conv2D(8, 3, 3, activation='relu', border_mode='same')(x)\n",
    "encoded = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(8, 3, 3, activation='relu', border_mode='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, 3, 3, activation='relu', border_mode='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning pre training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Input,Flatten,Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications import VGG16\n",
    "\n",
    "#LOAD PRETRAINED MODEL \n",
    "input_tensor=Input(shape=x_train.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor )\n",
    "features_train = modelVGG.predict(x_train)\n",
    "features_test = modelVGG.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelVGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = modelVGG.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "#https://keras.io/layers/normalization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_20 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               102500    \n",
      "=================================================================\n",
      "Total params: 633,956\n",
      "Trainable params: 630,884\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 3.6721 - acc: 0.2160 - val_loss: 2.7846 - val_acc: 0.3300\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.8317 - acc: 0.3132 - val_loss: 2.6391 - val_acc: 0.3488\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.5960 - acc: 0.3487 - val_loss: 2.5803 - val_acc: 0.3628\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.4554 - acc: 0.3703 - val_loss: 2.5412 - val_acc: 0.3706\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 2.3542 - acc: 0.3924 - val_loss: 2.5368 - val_acc: 0.3701\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.2656 - acc: 0.4061 - val_loss: 2.5280 - val_acc: 0.3743\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.2024 - acc: 0.4180 - val_loss: 2.5128 - val_acc: 0.3759\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 2.1220 - acc: 0.4342 - val_loss: 2.4949 - val_acc: 0.3793\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.0706 - acc: 0.4443 - val_loss: 2.4905 - val_acc: 0.3776\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.0011 - acc: 0.4588 - val_loss: 2.5070 - val_acc: 0.3785\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.9424 - acc: 0.4693 - val_loss: 2.5162 - val_acc: 0.3842\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.8933 - acc: 0.4822 - val_loss: 2.5132 - val_acc: 0.3852\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.8466 - acc: 0.4900 - val_loss: 2.5151 - val_acc: 0.3873\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.7960 - acc: 0.5031 - val_loss: 2.5386 - val_acc: 0.3848\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.7534 - acc: 0.5122 - val_loss: 2.5402 - val_acc: 0.3839\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.7069 - acc: 0.5216 - val_loss: 2.5520 - val_acc: 0.3862\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.6681 - acc: 0.5330 - val_loss: 2.5583 - val_acc: 0.3864\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.6382 - acc: 0.5407 - val_loss: 2.5719 - val_acc: 0.3822\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.5916 - acc: 0.5479 - val_loss: 2.5833 - val_acc: 0.3850\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.5611 - acc: 0.5580 - val_loss: 2.6020 - val_acc: 0.3852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d8903fc10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "optimizer_ = SGD(lr=0.01,momentum=0.9,decay=1e-6)\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,nb_epoch=20, batch_size=128,verbose=1,validation_data=(features_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy:', 0.3852)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(features_test, y_test,verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine tunning the last layers of vgg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_60 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 100)               102500    \n",
      "=================================================================\n",
      "Total params: 7,713,380\n",
      "Trainable params: 7,710,308\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LOAD PRETRAINED MODEL \n",
    "input_tensor=Input(shape=x_train.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor )\n",
    "\n",
    "salida_vgg = modelVGG.get_layer('block4_pool').output_shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512,(3, 3),input_shape=salida_vgg[1:],activation='relu',padding='same'))\n",
    "model.add(Conv2D(512,(3, 3),activation='relu',padding='same'))\n",
    "model.add(Conv2D(512,(3, 3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D((2, 2),strides=(2,2)))    \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "#delete last 4 layers of VGG16 and transfer the weight to new model\n",
    "modelVGG.layers.pop() #delete last maxpooling\n",
    "for i in np.arange(2,-1,-1):\n",
    "    last = modelVGG.layers.pop()\n",
    "    model.layers[i].set_weights(last.get_weights())\n",
    "    \n",
    "from keras.models import Model\n",
    "crop_modelVGG = Model(inputs=modelVGG.input, outputs=modelVGG.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = crop_modelVGG.predict(x_train)\n",
    "features_test = crop_modelVGG.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2, 2, 512)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 3.5162 - acc: 0.2141 - val_loss: 4.5538 - val_acc: 0.1687\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 2.7403 - acc: 0.3285 - val_loss: 3.3330 - val_acc: 0.2599\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 2.4660 - acc: 0.3810 - val_loss: 3.0097 - val_acc: 0.3091\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 2.3159 - acc: 0.4078 - val_loss: 2.3625 - val_acc: 0.3901\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 2.1864 - acc: 0.4350 - val_loss: 2.6770 - val_acc: 0.3600\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 2.0560 - acc: 0.4586 - val_loss: 2.2441 - val_acc: 0.4212\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.9507 - acc: 0.4754 - val_loss: 2.6159 - val_acc: 0.3780\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.8337 - acc: 0.4964 - val_loss: 2.2827 - val_acc: 0.4357\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.7313 - acc: 0.5201 - val_loss: 2.2304 - val_acc: 0.4448\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.6515 - acc: 0.5417 - val_loss: 2.2368 - val_acc: 0.4501\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 1.5710 - acc: 0.5571 - val_loss: 2.3132 - val_acc: 0.4378\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.4942 - acc: 0.5753 - val_loss: 2.3122 - val_acc: 0.4393\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.4184 - acc: 0.5906 - val_loss: 2.2882 - val_acc: 0.4622\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.3487 - acc: 0.6087 - val_loss: 2.2598 - val_acc: 0.4641\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.2801 - acc: 0.6266 - val_loss: 2.2770 - val_acc: 0.4644\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.2069 - acc: 0.6428 - val_loss: 2.3270 - val_acc: 0.4538\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.1306 - acc: 0.6638 - val_loss: 2.4070 - val_acc: 0.4600\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.0667 - acc: 0.6823 - val_loss: 2.5149 - val_acc: 0.4582\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.9954 - acc: 0.6989 - val_loss: 2.4954 - val_acc: 0.4579\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.9306 - acc: 0.7145 - val_loss: 2.5532 - val_acc: 0.4643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d8f96ee90>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_ = SGD(lr=0.01,momentum=0.9,decay=1e-6)\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,nb_epoch=20, batch_size=128,verbose=1,validation_data=(features_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy:', 0.4643)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(features_test, y_test,verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
