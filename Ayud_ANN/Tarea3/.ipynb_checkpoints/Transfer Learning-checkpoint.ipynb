{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_LABELS_LIST = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyboard\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e00d85610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i = 15\n",
    "print(CIFAR100_LABELS_LIST[y_train[i][0]])\n",
    "plt.imshow(x_train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=100)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_73 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               102500    \n",
      "=================================================================\n",
      "Total params: 4,363,396\n",
      "Trainable params: 4,363,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:],activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      " 5888/50000 [==>...........................] - ETA: 15s - loss: 4.6114 - acc: 0.0112"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-7e74a341dd51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/casapanshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer_ = keras.optimizers.SGD(lr=0.001,momentum=0.9) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, nb_epoch=12, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 4.3803 - acc: 0.0417 - val_loss: 3.9261 - val_acc: 0.1070\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 3.8220 - acc: 0.1171 - val_loss: 3.5267 - val_acc: 0.1739\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 3.4593 - acc: 0.1766 - val_loss: 3.2071 - val_acc: 0.2358\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 3.1303 - acc: 0.2400 - val_loss: 2.9454 - val_acc: 0.2828\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 2.8717 - acc: 0.2886 - val_loss: 2.7466 - val_acc: 0.3213\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 2.6496 - acc: 0.3307 - val_loss: 2.5653 - val_acc: 0.3541\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 2.4342 - acc: 0.3780 - val_loss: 2.5406 - val_acc: 0.3666\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 2.2312 - acc: 0.4187 - val_loss: 2.4248 - val_acc: 0.3925\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 2.0416 - acc: 0.4611 - val_loss: 2.3726 - val_acc: 0.3997\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.8397 - acc: 0.5038 - val_loss: 2.3977 - val_acc: 0.4008\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.6403 - acc: 0.5503 - val_loss: 2.4034 - val_acc: 0.4086\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.4564 - acc: 0.5903 - val_loss: 2.4180 - val_acc: 0.4082\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.2726 - acc: 0.6364 - val_loss: 2.4682 - val_acc: 0.4145\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.1175 - acc: 0.6743 - val_loss: 2.5692 - val_acc: 0.4032\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.9554 - acc: 0.7169 - val_loss: 2.6113 - val_acc: 0.4058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81b55c6250>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_ = keras.optimizers.SGD(lr=0.01,momentum=0.9) #probar con lr =0.1 sino gg\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, nb_epoch=15, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy:', 0.4068)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donde dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder pre training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 32, 3)         867       \n",
      "=================================================================\n",
      "Total params: 1,763\n",
      "Trainable params: 1,763\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.5555 - val_loss: 0.5309\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.5310 - val_loss: 0.5294\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.5302 - val_loss: 0.5291\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.5299 - val_loss: 0.5286\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.5296 - val_loss: 0.5288\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.5295 - val_loss: 0.5285\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.5294 - val_loss: 0.5282\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.5293 - val_loss: 0.5282\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.5292 - val_loss: 0.5281\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.5292 - val_loss: 0.5280\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.5291 - val_loss: 0.5280\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.5290 - val_loss: 0.5284\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.5289 - val_loss: 0.5278\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.5288 - val_loss: 0.5277\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.5288 - val_loss: 0.5276\n"
     ]
    }
   ],
   "source": [
    "#model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:],activation='relu'))\n",
    "#model.add(Conv2D(32, (3, 3),padding='same',activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "input_img = Input(shape=x_train.shape[1:])\n",
    "\n",
    "encoded1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "#x = MaxPooling2D((2, 2), border_mode='same')(x)\n",
    "#x = Conv2D(8, 3, 3, activation='relu', border_mode='same')(x)$\n",
    "#encoded = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "decoded1 = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(encoded1)\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "#x = Conv2D(16, 3, 3, activation='relu', border_mode='same')(x)\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "#decoded = Conv2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)\n",
    "\n",
    "autoencoder1 = Model(input_img, decoded1)\n",
    "autoencoder1.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder1.summary()\n",
    "\n",
    "autoencoder1.fit(x_train, x_train, epochs=15, batch_size=128,validation_data=(x_test, x_test))\n",
    "autoencoder1.save('autoencoder_layer1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5958127410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(autoencoder1.predict(x_train[:10])[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/lib/python2.7/site-packages/keras/models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "encoder1 = load_model(\"encoder_layer1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_encoded1 = encoder1.predict(x_train) #FORWARD PASS DATA THROUGH FIRST ENCODER\n",
    "#x_test_encoded1 = encoder1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_12:0' shape=(?, 32, 32, 3) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder1.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 32, 3)         867       \n",
      "=================================================================\n",
      "Total params: 20,259\n",
      "Trainable params: 18,496\n",
      "Non-trainable params: 1,763\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.0048 - val_loss: 0.0010\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 7.5698e-04 - val_loss: 5.6500e-04\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 5.4103e-04 - val_loss: 4.6798e-04\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 4.3165e-04 - val_loss: 3.5990e-04\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 3.7138e-04 - val_loss: 3.0664e-04\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 3.2299e-04 - val_loss: 2.6724e-04\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 2.9131e-04 - val_loss: 2.2916e-04\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 2.5372e-04 - val_loss: 9.6090e-04\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 2.4349e-04 - val_loss: 1.8590e-04\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 2.0387e-04 - val_loss: 1.8699e-04\n"
     ]
    }
   ],
   "source": [
    "###AUTOENCODER 2\n",
    "#x_train_encoded1 = encoder1.predict(x_train) #FORWARD PASS DATA THROUGH FIRST ENCODER\n",
    "#x_test_encoded1 = encoder1.predict(x_test)\n",
    "\n",
    "\n",
    "#input_img2 = Input(shape=encoder1.output_shape)#x_train_encoded1.shape[1:])\n",
    "encoded1 = autoencoder1.layers[1](autoencoder1.input)\n",
    "#AUTOENCODER2\n",
    "encoded2 = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded1) #sin filtros ni activaciones\n",
    "decoded2 = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded2) #sin foltros ni activaciones\n",
    "#finish autoencoder2\n",
    "decoded1 = autoencoder1.layers[-1](decoded2)\n",
    "\n",
    "\n",
    "autoencoder2 = Model(autoencoder1.input, decoded1) #all model\n",
    "\n",
    "#primer autoencoder fijo\n",
    "autoencoder2.layers[1].trainable=False\n",
    "autoencoder2.layers[-1].trainable=False\n",
    "\n",
    "autoencoder2.compile(optimizer='adam', loss='mse')\n",
    "autoencoder2.summary()\n",
    "\n",
    "autoencoder2.fit(x_train, x_train, epochs=10, batch_size=128,validation_data=(x_test, x_test))\n",
    "autoencoder2.save('autoencoder_layer2.h5')\n",
    "#encoder2.save('encoder_layer2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_77 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               102500    \n",
      "=================================================================\n",
      "Total params: 4,363,396\n",
      "Trainable params: 4,363,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#FINE TUNNING\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:],activation='relu'))\n",
    "model.layers[-1].set_weights(autoencoder1.layers[1].get_weights())\n",
    "model.add(Conv2D(32, (3, 3),padding='same',activation='relu'))\n",
    "model.layers[-1].set_weights(autoencoder2.layers[2].get_weights())\n",
    "#...#rest of the model\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.9828 - acc: 0.4754 - val_loss: 2.5458 - val_acc: 0.3751\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.9276 - acc: 0.4863 - val_loss: 2.5223 - val_acc: 0.3797\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.8734 - acc: 0.4965 - val_loss: 2.5309 - val_acc: 0.3808\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.8094 - acc: 0.5133 - val_loss: 2.5425 - val_acc: 0.3793\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.7526 - acc: 0.5237 - val_loss: 2.5217 - val_acc: 0.3900\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.7020 - acc: 0.5375 - val_loss: 2.5517 - val_acc: 0.3869\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.6378 - acc: 0.5512 - val_loss: 2.5577 - val_acc: 0.3866\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.5873 - acc: 0.5612 - val_loss: 2.5747 - val_acc: 0.3884\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.5315 - acc: 0.5761 - val_loss: 2.5419 - val_acc: 0.3863\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.4794 - acc: 0.5852 - val_loss: 2.5905 - val_acc: 0.3868\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.4240 - acc: 0.5996 - val_loss: 2.6062 - val_acc: 0.3893\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 1.3736 - acc: 0.6116 - val_loss: 2.6237 - val_acc: 0.3902\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.3190 - acc: 0.6237 - val_loss: 2.6302 - val_acc: 0.3876\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.2588 - acc: 0.6369 - val_loss: 2.6634 - val_acc: 0.3933\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.2100 - acc: 0.6509 - val_loss: 2.6563 - val_acc: 0.3932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81a99ba5d0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_ = keras.optimizers.SGD(lr=0.001,momentum=0.9) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=15, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 4.1847 - acc: 0.0677 - val_loss: 3.6828 - val_acc: 0.1488\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 3.5751 - acc: 0.1623 - val_loss: 3.2868 - val_acc: 0.2164\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 3.2138 - acc: 0.2268 - val_loss: 3.0133 - val_acc: 0.2741\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 2.9405 - acc: 0.2766 - val_loss: 2.7977 - val_acc: 0.3075\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 2.6887 - acc: 0.3296 - val_loss: 2.6567 - val_acc: 0.3383\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 2.4533 - acc: 0.3745 - val_loss: 2.5309 - val_acc: 0.3641\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 2.2378 - acc: 0.4178 - val_loss: 2.4718 - val_acc: 0.3827\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 2.0271 - acc: 0.4618 - val_loss: 2.4239 - val_acc: 0.3912\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 1.8242 - acc: 0.5072 - val_loss: 2.4248 - val_acc: 0.3965\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.6164 - acc: 0.5544 - val_loss: 2.4347 - val_acc: 0.4008\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.4273 - acc: 0.5957 - val_loss: 2.5305 - val_acc: 0.3877\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.2488 - acc: 0.6416 - val_loss: 2.5065 - val_acc: 0.4010\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 1.0688 - acc: 0.6851 - val_loss: 2.6491 - val_acc: 0.3986\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.9316 - acc: 0.7221 - val_loss: 2.7557 - val_acc: 0.4011\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.8042 - acc: 0.7591 - val_loss: 2.7959 - val_acc: 0.4046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81b41c94d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_ = keras.optimizers.SGD(lr=0.01,momentum=0.9) #probar con lr =0.1 sino gg\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=15, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy:', 0.4046)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning pre training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 13s 0us/step\n",
      "58900480/58889256 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Input,Flatten,Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications import VGG16\n",
    "\n",
    "#LOAD PRETRAINED MODEL \n",
    "input_tensor=Input(shape=x_train.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor )\n",
    "features_train = modelVGG.predict(x_train)\n",
    "features_test = modelVGG.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelVGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = modelVGG.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "#https://keras.io/layers/normalization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               102500    \n",
      "=================================================================\n",
      "Total params: 633,956\n",
      "Trainable params: 630,884\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 3.7336 - acc: 0.2008 - val_loss: 2.8729 - val_acc: 0.3102\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 2.9664 - acc: 0.2894 - val_loss: 2.6952 - val_acc: 0.3401\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 4s 70us/step - loss: 2.7265 - acc: 0.3256 - val_loss: 2.6503 - val_acc: 0.3478\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 4s 73us/step - loss: 2.5915 - acc: 0.3483 - val_loss: 2.6056 - val_acc: 0.3561\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 2.4803 - acc: 0.3658 - val_loss: 2.5987 - val_acc: 0.3619\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 2.3946 - acc: 0.3812 - val_loss: 2.5673 - val_acc: 0.3641\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 2.3273 - acc: 0.3958 - val_loss: 2.5533 - val_acc: 0.3714\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 2.2501 - acc: 0.4109 - val_loss: 2.5607 - val_acc: 0.3752\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 2.1946 - acc: 0.4225 - val_loss: 2.5570 - val_acc: 0.3748\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 2.1323 - acc: 0.4362 - val_loss: 2.5576 - val_acc: 0.3713\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.0826 - acc: 0.4462 - val_loss: 2.5419 - val_acc: 0.3794\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 2.0293 - acc: 0.4558 - val_loss: 2.5586 - val_acc: 0.3804\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.9801 - acc: 0.4678 - val_loss: 2.5713 - val_acc: 0.3776\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.9334 - acc: 0.4772 - val_loss: 2.5801 - val_acc: 0.3774\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.8848 - acc: 0.4880 - val_loss: 2.5780 - val_acc: 0.3844\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.8435 - acc: 0.4968 - val_loss: 2.5874 - val_acc: 0.3830\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 1.8003 - acc: 0.5041 - val_loss: 2.5903 - val_acc: 0.3863\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.7668 - acc: 0.5149 - val_loss: 2.6125 - val_acc: 0.3821\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 1.7331 - acc: 0.5195 - val_loss: 2.6400 - val_acc: 0.3776\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 4s 73us/step - loss: 1.6905 - acc: 0.5311 - val_loss: 2.6484 - val_acc: 0.3817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f804c08cf90>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "optimizer_ = SGD(lr=0.01,momentum=0.9)\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,nb_epoch=20, batch_size=128,verbose=1,validation_data=(features_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy:', 0.3852)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(features_test, y_test,verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine tunning the last layers of vgg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_84 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               102500    \n",
      "=================================================================\n",
      "Total params: 7,713,380\n",
      "Trainable params: 7,710,308\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LOAD PRETRAINED MODEL \n",
    "input_tensor=Input(shape=x_train.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor )\n",
    "\n",
    "salida_vgg = modelVGG.get_layer('block4_pool').output_shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512,(3, 3),input_shape=salida_vgg[1:],activation='relu',padding='same'))\n",
    "model.add(Conv2D(512,(3, 3),activation='relu',padding='same'))\n",
    "model.add(Conv2D(512,(3, 3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D((2, 2),strides=(2,2)))    \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "#delete last 4 layers of VGG16 and transfer the weight to new model\n",
    "modelVGG.layers.pop() #delete last maxpooling\n",
    "import numpy as np\n",
    "for i in np.arange(2,-1,-1):\n",
    "    last = modelVGG.layers.pop()\n",
    "    model.layers[i].set_weights(last.get_weights())\n",
    "    \n",
    "from keras.models import Model\n",
    "crop_modelVGG = Model(inputs=modelVGG.input, outputs=modelVGG.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = crop_modelVGG.predict(x_train)\n",
    "features_test = crop_modelVGG.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2, 2, 512)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 15s 302us/step - loss: 3.5809 - acc: 0.2015 - val_loss: 4.7692 - val_acc: 0.1631\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 2.7858 - acc: 0.3194 - val_loss: 3.2118 - val_acc: 0.2866\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 12s 250us/step - loss: 2.5351 - acc: 0.3682 - val_loss: 2.6870 - val_acc: 0.3395\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 2.3536 - acc: 0.3985 - val_loss: 2.7065 - val_acc: 0.3362\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 2.2071 - acc: 0.4284 - val_loss: 2.4731 - val_acc: 0.3952\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 2.1143 - acc: 0.4436 - val_loss: 2.4339 - val_acc: 0.3989\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 1.9857 - acc: 0.4658 - val_loss: 2.3049 - val_acc: 0.4176\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 1.8771 - acc: 0.4875 - val_loss: 2.2773 - val_acc: 0.4267\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 1.7824 - acc: 0.5076 - val_loss: 2.1439 - val_acc: 0.4488\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.6928 - acc: 0.5293 - val_loss: 2.3146 - val_acc: 0.4303\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 1.6218 - acc: 0.5468 - val_loss: 2.0940 - val_acc: 0.4668\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.5204 - acc: 0.5670 - val_loss: 2.2377 - val_acc: 0.4610\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.4519 - acc: 0.5837 - val_loss: 2.2402 - val_acc: 0.4522\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.3858 - acc: 0.5999 - val_loss: 2.2485 - val_acc: 0.4556\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 1.3046 - acc: 0.6177 - val_loss: 2.2838 - val_acc: 0.4649\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 1.2456 - acc: 0.6331 - val_loss: 2.4006 - val_acc: 0.4603\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 1.1647 - acc: 0.6528 - val_loss: 2.4660 - val_acc: 0.4487\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 1.0998 - acc: 0.6711 - val_loss: 2.5454 - val_acc: 0.4491\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 1.0377 - acc: 0.6884 - val_loss: 2.4834 - val_acc: 0.4585\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 0.9671 - acc: 0.7055 - val_loss: 2.6953 - val_acc: 0.4481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f804f5466d0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ejecucion con 1060\n",
    "optimizer_ = SGD(lr=0.01,momentum=0.9)\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,nb_epoch=20, batch_size=128,verbose=1,validation_data=(features_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 3.5162 - acc: 0.2141 - val_loss: 4.5538 - val_acc: 0.1687\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 2.7403 - acc: 0.3285 - val_loss: 3.3330 - val_acc: 0.2599\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 2.4660 - acc: 0.3810 - val_loss: 3.0097 - val_acc: 0.3091\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 2.3159 - acc: 0.4078 - val_loss: 2.3625 - val_acc: 0.3901\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 2.1864 - acc: 0.4350 - val_loss: 2.6770 - val_acc: 0.3600\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 2.0560 - acc: 0.4586 - val_loss: 2.2441 - val_acc: 0.4212\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.9507 - acc: 0.4754 - val_loss: 2.6159 - val_acc: 0.3780\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.8337 - acc: 0.4964 - val_loss: 2.2827 - val_acc: 0.4357\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.7313 - acc: 0.5201 - val_loss: 2.2304 - val_acc: 0.4448\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.6515 - acc: 0.5417 - val_loss: 2.2368 - val_acc: 0.4501\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 1.5710 - acc: 0.5571 - val_loss: 2.3132 - val_acc: 0.4378\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.4942 - acc: 0.5753 - val_loss: 2.3122 - val_acc: 0.4393\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.4184 - acc: 0.5906 - val_loss: 2.2882 - val_acc: 0.4622\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.3487 - acc: 0.6087 - val_loss: 2.2598 - val_acc: 0.4641\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.2801 - acc: 0.6266 - val_loss: 2.2770 - val_acc: 0.4644\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.2069 - acc: 0.6428 - val_loss: 2.3270 - val_acc: 0.4538\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.1306 - acc: 0.6638 - val_loss: 2.4070 - val_acc: 0.4600\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.0667 - acc: 0.6823 - val_loss: 2.5149 - val_acc: 0.4582\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.9954 - acc: 0.6989 - val_loss: 2.4954 - val_acc: 0.4579\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.9306 - acc: 0.7145 - val_loss: 2.5532 - val_acc: 0.4643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d8f96ee90>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_ = SGD(lr=0.01,momentum=0.9,decay=1e-6)\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,nb_epoch=20, batch_size=128,verbose=1,validation_data=(features_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy:', 0.4643)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(features_test, y_test,verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
