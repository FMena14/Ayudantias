{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "def load_CIFAR_one(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "def load_CIFAR10(PATH):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(PATH, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_one(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    #add your Xval\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_one(os.path.join(PATH, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,ytrain,xtest,ytest = load_CIFAR10('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "x_train = xtrain.reshape((xtrain.shape[0],3,32,32))\n",
    "x_train = x_train.transpose([0, 2, 3, 1]) #only if 'tf' dim-ordering is to be used\n",
    "x_test= xtest.reshape((xtest.shape[0],3,32,32))\n",
    "x_test= x_test.transpose([0, 2, 3, 1])#remove if 'th' dim-ordering is to be used\n",
    "y_train = keras.utils.to_categorical(ytrain, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(ytest, num_classes=10)\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.23137255, 0.24313725, 0.24705882],\n",
       "         [0.16862745, 0.18039216, 0.17647059],\n",
       "         [0.19607843, 0.18823529, 0.16862745],\n",
       "         ...,\n",
       "         [0.61960784, 0.51764706, 0.42352941],\n",
       "         [0.59607843, 0.49019608, 0.4       ],\n",
       "         [0.58039216, 0.48627451, 0.40392157]],\n",
       "\n",
       "        [[0.0627451 , 0.07843137, 0.07843137],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509804, 0.21568627],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117647, 0.22352941]],\n",
       "\n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215686, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941176, 0.19607843],\n",
       "         [0.47058824, 0.32941176, 0.19607843],\n",
       "         [0.42745098, 0.28627451, 0.16470588]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.81568627, 0.66666667, 0.37647059],\n",
       "         [0.78823529, 0.6       , 0.13333333],\n",
       "         [0.77647059, 0.63137255, 0.10196078],\n",
       "         ...,\n",
       "         [0.62745098, 0.52156863, 0.2745098 ],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333333, 0.07843137]],\n",
       "\n",
       "        [[0.70588235, 0.54509804, 0.37647059],\n",
       "         [0.67843137, 0.48235294, 0.16470588],\n",
       "         [0.72941176, 0.56470588, 0.11764706],\n",
       "         ...,\n",
       "         [0.72156863, 0.58039216, 0.36862745],\n",
       "         [0.38039216, 0.24313725, 0.13333333],\n",
       "         [0.3254902 , 0.20784314, 0.13333333]],\n",
       "\n",
       "        [[0.69411765, 0.56470588, 0.45490196],\n",
       "         [0.65882353, 0.50588235, 0.36862745],\n",
       "         [0.70196078, 0.55686275, 0.34117647],\n",
       "         ...,\n",
       "         [0.84705882, 0.72156863, 0.54901961],\n",
       "         [0.59215686, 0.4627451 , 0.32941176],\n",
       "         [0.48235294, 0.36078431, 0.28235294]]],\n",
       "\n",
       "\n",
       "       [[[0.60392157, 0.69411765, 0.73333333],\n",
       "         [0.49411765, 0.5372549 , 0.53333333],\n",
       "         [0.41176471, 0.40784314, 0.37254902],\n",
       "         ...,\n",
       "         [0.35686275, 0.37254902, 0.27843137],\n",
       "         [0.34117647, 0.35294118, 0.27843137],\n",
       "         [0.30980392, 0.31764706, 0.2745098 ]],\n",
       "\n",
       "        [[0.54901961, 0.62745098, 0.6627451 ],\n",
       "         [0.56862745, 0.6       , 0.60392157],\n",
       "         [0.49019608, 0.49019608, 0.4627451 ],\n",
       "         ...,\n",
       "         [0.37647059, 0.38823529, 0.30588235],\n",
       "         [0.30196078, 0.31372549, 0.24313725],\n",
       "         [0.27843137, 0.28627451, 0.23921569]],\n",
       "\n",
       "        [[0.54901961, 0.60784314, 0.64313725],\n",
       "         [0.54509804, 0.57254902, 0.58431373],\n",
       "         [0.45098039, 0.45098039, 0.43921569],\n",
       "         ...,\n",
       "         [0.30980392, 0.32156863, 0.25098039],\n",
       "         [0.26666667, 0.2745098 , 0.21568627],\n",
       "         [0.2627451 , 0.27058824, 0.21568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.68627451, 0.65490196, 0.65098039],\n",
       "         [0.61176471, 0.60392157, 0.62745098],\n",
       "         [0.60392157, 0.62745098, 0.66666667],\n",
       "         ...,\n",
       "         [0.16470588, 0.13333333, 0.14117647],\n",
       "         [0.23921569, 0.20784314, 0.22352941],\n",
       "         [0.36470588, 0.3254902 , 0.35686275]],\n",
       "\n",
       "        [[0.64705882, 0.60392157, 0.50196078],\n",
       "         [0.61176471, 0.59607843, 0.50980392],\n",
       "         [0.62352941, 0.63137255, 0.55686275],\n",
       "         ...,\n",
       "         [0.40392157, 0.36470588, 0.37647059],\n",
       "         [0.48235294, 0.44705882, 0.47058824],\n",
       "         [0.51372549, 0.4745098 , 0.51372549]],\n",
       "\n",
       "        [[0.63921569, 0.58039216, 0.47058824],\n",
       "         [0.61960784, 0.58039216, 0.47843137],\n",
       "         [0.63921569, 0.61176471, 0.52156863],\n",
       "         ...,\n",
       "         [0.56078431, 0.52156863, 0.54509804],\n",
       "         [0.56078431, 0.5254902 , 0.55686275],\n",
       "         [0.56078431, 0.52156863, 0.56470588]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44313725, 0.47058824, 0.43921569],\n",
       "         [0.43529412, 0.4627451 , 0.43529412],\n",
       "         [0.41176471, 0.43921569, 0.41568627],\n",
       "         ...,\n",
       "         [0.28235294, 0.31764706, 0.31372549],\n",
       "         [0.28235294, 0.31372549, 0.30980392],\n",
       "         [0.28235294, 0.31372549, 0.30980392]],\n",
       "\n",
       "        [[0.43529412, 0.4627451 , 0.43137255],\n",
       "         [0.40784314, 0.43529412, 0.40784314],\n",
       "         [0.38823529, 0.41568627, 0.38431373],\n",
       "         ...,\n",
       "         [0.26666667, 0.29411765, 0.28627451],\n",
       "         [0.2745098 , 0.29803922, 0.29411765],\n",
       "         [0.30588235, 0.32941176, 0.32156863]],\n",
       "\n",
       "        [[0.41568627, 0.44313725, 0.41176471],\n",
       "         [0.38823529, 0.41568627, 0.38431373],\n",
       "         [0.37254902, 0.4       , 0.36862745],\n",
       "         ...,\n",
       "         [0.30588235, 0.33333333, 0.3254902 ],\n",
       "         [0.30980392, 0.33333333, 0.3254902 ],\n",
       "         [0.31372549, 0.3372549 , 0.32941176]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.1372549 , 0.69803922, 0.92156863],\n",
       "         [0.15686275, 0.69019608, 0.9372549 ],\n",
       "         [0.16470588, 0.69019608, 0.94509804],\n",
       "         ...,\n",
       "         [0.38823529, 0.69411765, 0.85882353],\n",
       "         [0.30980392, 0.57647059, 0.77254902],\n",
       "         [0.34901961, 0.58039216, 0.74117647]],\n",
       "\n",
       "        [[0.22352941, 0.71372549, 0.91764706],\n",
       "         [0.17254902, 0.72156863, 0.98039216],\n",
       "         [0.19607843, 0.71764706, 0.94117647],\n",
       "         ...,\n",
       "         [0.61176471, 0.71372549, 0.78431373],\n",
       "         [0.55294118, 0.69411765, 0.80784314],\n",
       "         [0.45490196, 0.58431373, 0.68627451]],\n",
       "\n",
       "        [[0.38431373, 0.77254902, 0.92941176],\n",
       "         [0.25098039, 0.74117647, 0.98823529],\n",
       "         [0.27058824, 0.75294118, 0.96078431],\n",
       "         ...,\n",
       "         [0.7372549 , 0.76470588, 0.80784314],\n",
       "         [0.46666667, 0.52941176, 0.57647059],\n",
       "         [0.23921569, 0.30980392, 0.35294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28627451, 0.30980392, 0.30196078],\n",
       "         [0.20784314, 0.24705882, 0.26666667],\n",
       "         [0.21176471, 0.26666667, 0.31372549],\n",
       "         ...,\n",
       "         [0.06666667, 0.15686275, 0.25098039],\n",
       "         [0.08235294, 0.14117647, 0.2       ],\n",
       "         [0.12941176, 0.18823529, 0.19215686]],\n",
       "\n",
       "        [[0.23921569, 0.26666667, 0.29411765],\n",
       "         [0.21568627, 0.2745098 , 0.3372549 ],\n",
       "         [0.22352941, 0.30980392, 0.40392157],\n",
       "         ...,\n",
       "         [0.09411765, 0.18823529, 0.28235294],\n",
       "         [0.06666667, 0.1372549 , 0.20784314],\n",
       "         [0.02745098, 0.09019608, 0.1254902 ]],\n",
       "\n",
       "        [[0.17254902, 0.21960784, 0.28627451],\n",
       "         [0.18039216, 0.25882353, 0.34509804],\n",
       "         [0.19215686, 0.30196078, 0.41176471],\n",
       "         ...,\n",
       "         [0.10588235, 0.20392157, 0.30196078],\n",
       "         [0.08235294, 0.16862745, 0.25882353],\n",
       "         [0.04705882, 0.12156863, 0.19607843]]],\n",
       "\n",
       "\n",
       "       [[[0.74117647, 0.82745098, 0.94117647],\n",
       "         [0.72941176, 0.81568627, 0.9254902 ],\n",
       "         [0.7254902 , 0.81176471, 0.92156863],\n",
       "         ...,\n",
       "         [0.68627451, 0.76470588, 0.87843137],\n",
       "         [0.6745098 , 0.76078431, 0.87058824],\n",
       "         [0.6627451 , 0.76078431, 0.8627451 ]],\n",
       "\n",
       "        [[0.76078431, 0.82352941, 0.9372549 ],\n",
       "         [0.74901961, 0.81176471, 0.9254902 ],\n",
       "         [0.74509804, 0.80784314, 0.92156863],\n",
       "         ...,\n",
       "         [0.67843137, 0.75294118, 0.8627451 ],\n",
       "         [0.67058824, 0.74901961, 0.85490196],\n",
       "         [0.65490196, 0.74509804, 0.84705882]],\n",
       "\n",
       "        [[0.81568627, 0.85882353, 0.95686275],\n",
       "         [0.80392157, 0.84705882, 0.94117647],\n",
       "         [0.8       , 0.84313725, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.68627451, 0.74901961, 0.85098039],\n",
       "         [0.6745098 , 0.74509804, 0.84705882],\n",
       "         [0.6627451 , 0.74901961, 0.84313725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.81176471, 0.78039216, 0.70980392],\n",
       "         [0.79607843, 0.76470588, 0.68627451],\n",
       "         [0.79607843, 0.76862745, 0.67843137],\n",
       "         ...,\n",
       "         [0.52941176, 0.51764706, 0.49803922],\n",
       "         [0.63529412, 0.61960784, 0.58823529],\n",
       "         [0.65882353, 0.63921569, 0.59215686]],\n",
       "\n",
       "        [[0.77647059, 0.74509804, 0.66666667],\n",
       "         [0.74117647, 0.70980392, 0.62352941],\n",
       "         [0.70588235, 0.6745098 , 0.57647059],\n",
       "         ...,\n",
       "         [0.69803922, 0.67058824, 0.62745098],\n",
       "         [0.68627451, 0.6627451 , 0.61176471],\n",
       "         [0.68627451, 0.6627451 , 0.60392157]],\n",
       "\n",
       "        [[0.77647059, 0.74117647, 0.67843137],\n",
       "         [0.74117647, 0.70980392, 0.63529412],\n",
       "         [0.69803922, 0.66666667, 0.58431373],\n",
       "         ...,\n",
       "         [0.76470588, 0.72156863, 0.6627451 ],\n",
       "         [0.76862745, 0.74117647, 0.67058824],\n",
       "         [0.76470588, 0.74509804, 0.67058824]]],\n",
       "\n",
       "\n",
       "       [[[0.89803922, 0.89803922, 0.9372549 ],\n",
       "         [0.9254902 , 0.92941176, 0.96862745],\n",
       "         [0.91764706, 0.9254902 , 0.96862745],\n",
       "         ...,\n",
       "         [0.85098039, 0.85882353, 0.91372549],\n",
       "         [0.86666667, 0.8745098 , 0.91764706],\n",
       "         [0.87058824, 0.8745098 , 0.91372549]],\n",
       "\n",
       "        [[0.87058824, 0.86666667, 0.89803922],\n",
       "         [0.9372549 , 0.9372549 , 0.97647059],\n",
       "         [0.91372549, 0.91764706, 0.96470588],\n",
       "         ...,\n",
       "         [0.8745098 , 0.8745098 , 0.9254902 ],\n",
       "         [0.89019608, 0.89411765, 0.93333333],\n",
       "         [0.82352941, 0.82745098, 0.8627451 ]],\n",
       "\n",
       "        [[0.83529412, 0.80784314, 0.82745098],\n",
       "         [0.91764706, 0.90980392, 0.9372549 ],\n",
       "         [0.90588235, 0.91372549, 0.95686275],\n",
       "         ...,\n",
       "         [0.8627451 , 0.8627451 , 0.90980392],\n",
       "         [0.8627451 , 0.85882353, 0.90980392],\n",
       "         [0.79215686, 0.79607843, 0.84313725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58823529, 0.56078431, 0.52941176],\n",
       "         [0.54901961, 0.52941176, 0.49803922],\n",
       "         [0.51764706, 0.49803922, 0.47058824],\n",
       "         ...,\n",
       "         [0.87843137, 0.87058824, 0.85490196],\n",
       "         [0.90196078, 0.89411765, 0.88235294],\n",
       "         [0.94509804, 0.94509804, 0.93333333]],\n",
       "\n",
       "        [[0.5372549 , 0.51764706, 0.49411765],\n",
       "         [0.50980392, 0.49803922, 0.47058824],\n",
       "         [0.49019608, 0.4745098 , 0.45098039],\n",
       "         ...,\n",
       "         [0.70980392, 0.70588235, 0.69803922],\n",
       "         [0.79215686, 0.78823529, 0.77647059],\n",
       "         [0.83137255, 0.82745098, 0.81176471]],\n",
       "\n",
       "        [[0.47843137, 0.46666667, 0.44705882],\n",
       "         [0.4627451 , 0.45490196, 0.43137255],\n",
       "         [0.47058824, 0.45490196, 0.43529412],\n",
       "         ...,\n",
       "         [0.70196078, 0.69411765, 0.67843137],\n",
       "         [0.64313725, 0.64313725, 0.63529412],\n",
       "         [0.63921569, 0.63921569, 0.63137255]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe954236f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,141,514\n",
      "Trainable params: 2,141,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 1.4473 - acc: 0.4839 - val_loss: 1.2517 - val_acc: 0.5600\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 1.0032 - acc: 0.6487 - val_loss: 0.8958 - val_acc: 0.6882\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.8091 - acc: 0.7200 - val_loss: 1.0023 - val_acc: 0.6542\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.6544 - acc: 0.7736 - val_loss: 0.9104 - val_acc: 0.7021\n",
      "Epoch 5/15\n",
      "44672/50000 [=========================>....] - ETA: 1s - loss: 0.5157 - acc: 0.8213"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, rmsprop\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=64,nb_epoch=15, validation_data=(x_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 150)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbin=150\n",
    "bins = np.linspace(0, 1, nbin+1)\n",
    "\n",
    "list_histograms = []\n",
    "for image in x_train:\n",
    "    imhist, bin_edges = np.histogram(image, bins=bins, density=True)\n",
    "    imhist = imhist * np.diff(bin_edges)\n",
    "    list_histograms.append(imhist)\n",
    "array_histograms = np.asarray(list_histograms)\n",
    "array_histograms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f210e5ca5d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f210e5ca510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(np.arange(150),array_histograms[0],label=label_names[ytrain[0]])\n",
    "plt.bar(np.arange(150),array_histograms[1],label=label_names[ytrain[1]])\n",
    "plt.bar(np.arange(150),array_histograms[5],label=label_names[ytrain[5]])\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(array_histograms)\n",
    "array_histograms = scaler.transform(array_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 2.1458\n",
      "Epoch 2/300\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 2.0765\n",
      "Epoch 3/300\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 2.0498\n",
      "Epoch 4/300\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 2.0282\n",
      "Epoch 5/300\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 2.0099\n",
      "Epoch 6/300\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.9944\n",
      "Epoch 7/300\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 1.9792\n",
      "Epoch 8/300\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 1.9619\n",
      "Epoch 9/300\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 1.9471\n",
      "Epoch 10/300\n",
      "50000/50000 [==============================] - 14s 279us/step - loss: 1.9267\n",
      "Epoch 11/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.9073\n",
      "Epoch 12/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.8852\n",
      "Epoch 13/300\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.8605\n",
      "Epoch 14/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.8384\n",
      "Epoch 15/300\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.8143\n",
      "Epoch 16/300\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.7856\n",
      "Epoch 17/300\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 1.7560\n",
      "Epoch 18/300\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.7267\n",
      "Epoch 19/300\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 1.6998\n",
      "Epoch 20/300\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 1.6643\n",
      "Epoch 21/300\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 1.6396\n",
      "Epoch 22/300\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 1.6045\n",
      "Epoch 23/300\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 1.5733\n",
      "Epoch 24/300\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.5479\n",
      "Epoch 25/300\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.5190\n",
      "Epoch 26/300\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4910\n",
      "Epoch 27/300\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.4609\n",
      "Epoch 28/300\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 1.4361\n",
      "Epoch 29/300\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4063\n",
      "Epoch 30/300\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.3833\n",
      "Epoch 31/300\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 1.3617\n",
      "Epoch 32/300\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 1.3338\n",
      "Epoch 33/300\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.3181\n",
      "Epoch 34/300\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 1.2902\n",
      "Epoch 35/300\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 1.2755\n",
      "Epoch 36/300\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.2563\n",
      "Epoch 37/300\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 1.2371\n",
      "Epoch 38/300\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.2165\n",
      "Epoch 39/300\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.1947\n",
      "Epoch 40/300\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.1834\n",
      "Epoch 41/300\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 1.1678\n",
      "Epoch 42/300\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.1484\n",
      "Epoch 43/300\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.1420\n",
      "Epoch 44/300\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.1183\n",
      "Epoch 45/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 1.1072\n",
      "Epoch 46/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 1.0891\n",
      "Epoch 47/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 1.0844\n",
      "Epoch 48/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 1.0689\n",
      "Epoch 49/300\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.0551\n",
      "Epoch 50/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.0375\n",
      "Epoch 51/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 1.0347\n",
      "Epoch 52/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.0174\n",
      "Epoch 53/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.0076\n",
      "Epoch 54/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 0.9952\n",
      "Epoch 55/300\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 0.9890\n",
      "Epoch 56/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 0.9753\n",
      "Epoch 57/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 0.9721\n",
      "Epoch 58/300\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 0.9609\n",
      "Epoch 59/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 0.9480\n",
      "Epoch 60/300\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 0.9382\n",
      "Epoch 61/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 0.9269\n",
      "Epoch 62/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 0.9123\n",
      "Epoch 63/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 0.9123\n",
      "Epoch 64/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 0.9043\n",
      "Epoch 65/300\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 0.8890\n",
      "Epoch 66/300\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 0.8831\n",
      "Epoch 67/300\n",
      "50000/50000 [==============================] - 13s 250us/step - loss: 0.8786\n",
      "Epoch 68/300\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.8667\n",
      "Epoch 69/300\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 0.8528\n",
      "Epoch 70/300\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 0.8483\n",
      "Epoch 71/300\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 0.8366\n",
      "Epoch 72/300\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 0.8427\n",
      "Epoch 73/300\n",
      "35776/50000 [====================>.........] - ETA: 4s - loss: 0.8150"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-71a3f7723f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_histograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=array_histograms.shape[1],activation='relu'))\n",
    "#model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "\n",
    "model.fit(array_histograms, y_train, epochs=300,verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 57s 113ms/step - loss: 0.9539 - val_loss: 0.9716\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.8238 - val_loss: 0.8427\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 54s 107ms/step - loss: 0.7700 - val_loss: 0.8298\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 0.7437 - val_loss: 0.9256\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 0.7293 - val_loss: 0.7694\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 0.7050 - val_loss: 0.8828\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 53s 107ms/step - loss: 0.6830 - val_loss: 0.7650\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 0.6745 - val_loss: 0.8091\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.6591 - val_loss: 0.7704\n",
      "Epoch 10/10\n",
      " 53/500 [==>...........................] - ETA: 50s - loss: 0.6427"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e712b54f9df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     vertical_flip=False) # randomly flip images\n\u001b[1;32m     15\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1251\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2242\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2243\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/panshop/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images (degrees, 0 to 180)\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of width)\n",
    "    height_shift_range=0.1, # randomly shift images vertically (fraction of height)\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False) # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),steps_per_epoch=x_train.shape[0]// batch_size, epochs=epochs,validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
